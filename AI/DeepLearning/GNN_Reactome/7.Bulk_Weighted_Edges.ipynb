{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbbf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Linear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3e45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m device\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\n",
      "File \u001b[0;32m~/software/miniconda3/envs/R4/lib/python3.9/site-packages/torch/cuda/__init__.py:350\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    348\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/software/miniconda3/envs/R4/lib/python3.9/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "#device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764f83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7b107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features,hidden_channels,num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels,num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. 获得节点嵌入\n",
    "        x = self.conv1(x, edge_index,edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index,edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index,edge_weight)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)   # [batch_size, hidden_channels]\n",
    "        \n",
    "        # 3. 分类器\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1586d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc820de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_USE_CUDA_DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9513ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGHV3-11,IGKV1D-33,SYK,SH3KBP1,IGHV1-69,IGLV1-47,IGKC,GRB2,IGHV2-70,IGLC7,IGKV3-11,IGHM,IGLV1-51,IGLV1-44,IGKV3-20,IGKV2D-28,IGKV2-30,NCK1,IGHV2-5,IGLC3,IGKV1-12,IGLV6-57,IGLV1-40,IGHD,IGKV2D-40,SOS1,IGLV3-25,IGHV3-23,IGHV1-2,IGLV2-14,IGKV2-28,IGKV1D-16,IGLV3-19,IGHV4-59,IGLV2-23,IGKV1D-12,IGHV3-33,IGLC1,BLNK,PLCG2,IGKV2D-30,IGLV3-27,IGKV3-15,IGLV2-11,IGHV3-48,IGHV3-9,BTK,IGLV2-8,IGKV1-17,IGKV3D-20,IGKV1-39,IGHV3-13,IGKV1-16,IGKV1D-39,IGHV4-34,IGKV2-29,IGLV7-43,IGLC6,IGKV4-1,IGLV3-1,IGKV5-2,CD79A,IGHV1-46,IGLV3-21,IGKV1-33,CD79B,IGKV1-5,IGHV4-39,VAV1,IGHV3-7,IGLC2,IGHV3-53,IGHV3-30\n"
     ]
    }
   ],
   "source": [
    "## 读取reaction包含的基因\n",
    "ReactionGeneFile = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.ProteinReactionNodes.txt\"\n",
    "ReactionGene = pd.read_csv(ReactionGeneFile,header=None,sep='\\t')\n",
    "ReactionGene.columns = [\"Reaction\",\"Gene\"]\n",
    "ReactionGene_dict = dict(zip(ReactionGene[\"Reaction\"],ReactionGene[\"Gene\"])) ## Reaction 对应的Gene\n",
    "print (ReactionGene_dict['R-HSA-1112666'])\n",
    "del ReactionGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7750b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11714\n",
      "tensor([[11573, 11462,     3,  ...,  6095,  9849,  9046],\n",
      "        [    0,     1,     2,  ..., 11713, 11713, 11713]])\n"
     ]
    }
   ],
   "source": [
    "edges_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.edges.txt\"\n",
    "edges = pd.read_csv(edges_file,header=None,sep=\"\\t\")\n",
    "edges.columns = [\"edge1\",\"edge2\",\"edge1_type\",\"edge2_type\"] \n",
    "uniq_output_nodes = sorted(list(set(edges[\"edge2\"].tolist()))) ## 取得唯一入度的点\n",
    "uniq_nodes = sorted(list(set(edges[\"edge1\"].tolist()) | set(edges[\"edge2\"].tolist())))\n",
    "print (len(uniq_nodes))\n",
    "edges = torch.load(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/Reactome_reaction_edges.pt\")\n",
    "print (edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f563fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 23520)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## 读取 IBD不同药物反应的bulk数据\n",
    "metainfo = pd.read_csv(\"/public/data/scDT/SingleCellDownload/IBD/Treatment_Bulk/Bulk_Anti-TNF/GSE16879/GSE16879.metainfo\",header=0,sep=',')\n",
    "#labels = [\"Control\",\"BeforeT_Yes\",\"BeforeT_No\"]\n",
    "labels = [\"BeforeT_Yes\",\"BeforeT_No\"]\n",
    "metainfo = metainfo[metainfo[\"group\"].isin(labels)].reset_index(drop=True)\n",
    "bulk_exp = pd.read_csv(\"/public/data/scDT/SingleCellDownload/IBD/Treatment_Bulk/Bulk_Anti-TNF/GSE16879/GSE16879.exp.csv\",header=0,sep=',',index_col=0)\n",
    "bulk_exp = bulk_exp.T\n",
    "print (bulk_exp.shape)\n",
    "bulk_genelist = bulk_exp.columns\n",
    "sample_full_labels = sorted(list(set(metainfo[\"group\"].tolist())))\n",
    "sample_full_labels_dict = dict(zip(sample_full_labels,range(len(sample_full_labels)))) ## label对应的index\n",
    "sample_dict = dict(zip(metainfo[\"SampleName\"],metainfo[\"group\"]))\n",
    "#list_labels = []\n",
    "#for x in range(len(sample_full_labels)):\n",
    "#    list_labels.append([x])\n",
    "#list_labels_tensor = torch.tensor(list_labels,dtype=torch.int64)\n",
    "print (sample_full_labels_dict[sample_dict[\"GSM364647\"]])\n",
    "#print (list_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_full_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9911ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_full_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f770193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneSymbol      A1BG  A1BG-AS1      A1CF       A2M   A2M-AS1\n",
      "GSM364627   4.380101  4.419979  8.879925  6.624456  2.997803\n",
      "GSM364628   3.772397  4.421832  8.280027  5.958338  3.119549\n",
      "GSM364629   3.630654  4.297836  8.598125  6.577818  2.972677\n",
      "GSM364630   3.779094  4.596442  9.035859  5.863000  2.786366\n",
      "GSM364631   3.688025  4.582495  8.553964  5.824698  2.802469\n",
      "(61, 23520)\n"
     ]
    }
   ],
   "source": [
    "print (bulk_exp.iloc[0:5,0:5])\n",
    "select_sample = metainfo[metainfo[\"group\"].isin(labels)][\"SampleName\"]\n",
    "bulk_exp_select = bulk_exp[bulk_exp.index.isin(select_sample)]\n",
    "sample_index_dict = dict(zip(bulk_exp_select.index,range(bulk_exp_select.shape[0]))) ## 将id 同index 存为字典\n",
    "print (bulk_exp_select.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1af3873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18  17:00:49\n",
      "2023-10-18  17:01:31\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0 -1.360485 -0.966420  0.807790  0.807790  0.597877 -0.217869 -1.249992   \n",
      "1  0.717703  0.350494 -2.191718 -2.191718 -0.254256 -0.526675 -0.430885   \n",
      "2 -1.136742 -1.381867 -0.081990 -0.081990 -0.852702 -1.470781 -1.692378   \n",
      "3 -0.508200 -1.551293 -0.863291 -0.863291 -0.859609 -1.892099 -2.228293   \n",
      "4 -1.435456 -0.690978 -2.385350 -2.385350 -1.446189 -2.176223 -1.466531   \n",
      "5 -0.191810 -0.623369 -0.596393 -0.596393 -0.310721 -0.221350 -0.381194   \n",
      "6  1.216349 -0.413629  0.231225  0.231225 -0.885601 -0.382622  1.186200   \n",
      "7  2.719679 -0.513786  0.034036  0.034036 -0.941039  0.612446  0.273110   \n",
      "8 -0.458633 -0.150840 -0.571838 -0.571838 -0.545757  2.573742  1.445098   \n",
      "9  1.482150 -0.035414  0.505400  0.505400 -0.846685  1.097248  0.755357   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.217869 -1.033377  1.046676  \n",
      "1 -0.526675  0.313569 -0.795221  \n",
      "2 -1.470781 -1.366306  1.120217  \n",
      "3 -1.892099 -0.344552 -0.424550  \n",
      "4 -2.176223 -0.395976 -0.141280  \n",
      "5 -0.221350  0.419513  0.250754  \n",
      "6 -0.382622 -0.029055  2.337990  \n",
      "7  0.612446  0.429078  1.851414  \n",
      "8  2.573742  0.607118 -2.256408  \n",
      "9  1.097248 -0.478126  1.565580  \n",
      "(61, 11714)\n"
     ]
    }
   ],
   "source": [
    "## 对于每一个reaction , PCA 得到的主成分 PCA1值\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## 对于每一个reaction , PCA 得到的主成分 PCA1值\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pca = PCA(n_components=2)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "sample_reaction_pca = pd.DataFrame()\n",
    "n = 0\n",
    "reaction_PCA_values = []\n",
    "for node in iter(uniq_nodes): ## 计算所有reaction节点 对应的PCA1 values\n",
    "    #print (node)\n",
    "    #node = \"R-HSA-1006169\"\n",
    "    if (node in ReactionGene_dict.keys()):\n",
    "        genelist = ReactionGene_dict[node].split(\",\")\n",
    "        common_gene = list(set(genelist) & set(bulk_genelist))\n",
    "        ## 去除bulk中不存在的基因\n",
    "        sub_exp = bulk_exp_select.loc[:,common_gene]\n",
    "        #print (sub_exp)\n",
    "        if (sub_exp.shape[1] >= 2):\n",
    "            #sub_exp = sub_exp.values\n",
    "            sub_exp = StandardScaler().fit_transform(sub_exp.values)\n",
    "            principalComponents = pca.fit_transform(sub_exp)\n",
    "            PCA_values =  pd.DataFrame(data = principalComponents,columns = [\"PCA1\",\"PCA2\"])\n",
    "            node_PCA_values = PCA_values[\"PCA1\"]\n",
    "        elif (sub_exp.shape[1] == 1): ## 如果reaction中只包含一个基因，无法做PCA，则对该基因表达量进行标准化\n",
    "            sub_exp = StandardScaler().fit_transform(sub_exp.values)\n",
    "            node_PCA_values = pd.DataFrame(data = sub_exp, columns=[\"PCA1\"])\n",
    "            #print (node_PCA_values)\n",
    "        else:\n",
    "            node_PCA_values = pd.DataFrame(np.zeros((bulk_exp_select.shape[0],1)),columns=[\"PCA1\"])\n",
    "    else:\n",
    "        node_PCA_values = pd.DataFrame(np.zeros((bulk_exp_select.shape[0],1)),columns=[\"PCA1\"])\n",
    "    reaction_PCA_values.append(node_PCA_values)\n",
    "    #sample_reaction_pca = pd.concat([sample_reaction_pca,node_PCA_values],axis=1,join='outer',ignore_index=True)\n",
    "    #n += 1\n",
    "    #if n >3:break\n",
    "    #break\n",
    "sample_reaction_pca = pd.concat(reaction_PCA_values,axis=1,join='outer',ignore_index=True)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "print (sample_reaction_pca.iloc[0:10,0:10])\n",
    "print (sample_reaction_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40c3328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47    GSM423061\n",
      "6     GSM364639\n",
      "31    GSM423023\n",
      "2     GSM364635\n",
      "29    GSM423019\n",
      "44    GSM423055\n",
      "26    GSM423013\n",
      "33    GSM423027\n",
      "27    GSM423015\n",
      "35    GSM423031\n",
      "32    GSM423025\n",
      "49    GSM423065\n",
      "28    GSM423017\n",
      "0     GSM364633\n",
      "Name: SampleName, dtype: object\n",
      "BeforeT_Yes 14\n",
      "52    GSM423071\n",
      "37    GSM423035\n",
      "14    GSM364647\n",
      "56    GSM423079\n",
      "39    GSM423039\n",
      "23    GSM364656\n",
      "42    GSM423045\n",
      "21    GSM364654\n",
      "53    GSM423073\n",
      "9     GSM364642\n",
      "19    GSM364652\n",
      "8     GSM364641\n",
      "15    GSM364648\n",
      "36    GSM423033\n",
      "58    GSM423083\n",
      "51    GSM423069\n",
      "57    GSM423081\n",
      "Name: SampleName, dtype: object\n",
      "BeforeT_No 17\n",
      "31\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "## 根据选取一半不同标签样本作为微调的训练集 \n",
    "bulk_tuning_sets = []\n",
    "bulk_test_sets = []\n",
    "for group in labels:\n",
    "    bulk_group_sample = metainfo[metainfo[\"group\"] == group][\"SampleName\"]\n",
    "    tuning_sample = bulk_group_sample.sample(math.ceil(bulk_group_sample.shape[0]/2)) ## 一半且向上取整\n",
    "    print (tuning_sample)\n",
    "    tuning_sample_index = tuning_sample.index\n",
    "    print (group,len(tuning_sample))\n",
    "    for m in tuning_sample:\n",
    "        sampleName = m\n",
    "        sample_index = sample_index_dict[sampleName]\n",
    "        sample_value = sample_reaction_pca.loc[sample_index].values\n",
    "        sample_value = sample_value.reshape(sample_value.shape[0],1)\n",
    "        sample_node_feature = Data(x=torch.tensor(sample_value,dtype = torch.float32),y=torch.tensor(sample_full_labels_dict[sample_dict[sampleName]]),edge_index = edges)\n",
    "        bulk_tuning_sets.append(sample_node_feature)\n",
    "        \n",
    "    test_sample = pd.concat([bulk_group_sample,tuning_sample,tuning_sample]).drop_duplicates(keep=False)\n",
    "    for n in test_sample:\n",
    "        sampleName = n\n",
    "        sample_index = sample_index_dict[sampleName]\n",
    "        sample_value = sample_reaction_pca.loc[sample_index].values\n",
    "        sample_value = sample_value.reshape(sample_value.shape[0],1)\n",
    "        sample_node_feature = Data(x=torch.tensor(sample_value,dtype = torch.float32),y=torch.tensor(sample_full_labels_dict[sample_dict[sampleName]]),edge_index = edges)\n",
    "        bulk_test_sets.append(sample_node_feature)\n",
    "        \n",
    "print (len(bulk_tuning_sets))\n",
    "print (len(bulk_test_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03785d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sample_full_labels_dict)\n",
    "print (sample_index_dict[\"GSM364656\"])\n",
    "#print (sample_index_dict[\"GSM422967\"])\n",
    "print (sample_full_labels_dict[sample_dict[\"GSM364656\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97dfa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_tuning():\n",
    "    model_tuning.train() ## \n",
    "    for data in bulk_total_loader:\n",
    "        #print (data.y)\n",
    "        data = data.to(device)\n",
    "        #x = data.x.to(device)\n",
    "        #e = data.edge_index.to(device)\n",
    "        #b = data.batch.to(device)\n",
    "        #y = data.y.to(device)\n",
    "        optimizer_tuning.zero_grad()\n",
    "        out = model_tuning(data.x, data.edge_index,data.batch)\n",
    "        loss = criterion_tuning(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer_tuning.step()\n",
    "        \n",
    "        \n",
    "def test_tuning(loader):\n",
    "    model_tuning.eval()\n",
    "    correct = 0\n",
    "    for data in loader:                           # 批遍历测试集数据集。\n",
    "        data = data.to(device)\n",
    "        out = model_tuning(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        #print (pred,data.y)\n",
    "        correct += int((pred == data.y).sum())           # 检查真实标签\n",
    "    return correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0911d21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(1, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model_tuning = GNN(num_node_features=1,hidden_channels=64,num_classes=31)\n",
    "#checkpoint = torch.load('/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reaction.PCA.pth.tar')\n",
    "#model_tuning.load_state_dict(checkpoint[\"model\"])\n",
    "#model_tuning.eval()\n",
    "model_tuning = torch.load(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reaction.PCA_convEdgeWeight.1018.pt\",map_location=device)\n",
    "model_tuning.lin = Linear(64,2)\n",
    "print (model_tuning)\n",
    "for name,layer in model_tuning.named_parameters():\n",
    "    if (name == 'lin.weight' or (name == 'lin.bias')):\n",
    "        #print (name,layer)\n",
    "        layer.requires_grad = True\n",
    "    else:\n",
    "        layer.requires_grad = False\n",
    "model_tuning = model_tuning.to(device)\n",
    "#model_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_tuning.named_parameters(): print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc5375b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bulk_train_loader =  DataLoader(bulk_tuning_sets, batch_size=2,shuffle=True)\n",
    "#bulk_test_loader = DataLoader(bulk_test_sets, batch_size=2,shuffle=True)\n",
    "bulk_total_sets = bulk_tuning_sets + bulk_test_sets\n",
    "bulk_total_loader = DataLoader(bulk_total_sets,batch_size=1,shuffle=False)\n",
    "len(bulk_total_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b2ebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18  22:12:46\n",
      "2023-10-18  22:12:47\n",
      "Epoch: 001, Train Acc: 0.7541\n",
      "2023-10-18  22:12:49\n",
      "Epoch: 002, Train Acc: 0.7705\n",
      "2023-10-18  22:12:52\n",
      "Epoch: 003, Train Acc: 0.7377\n",
      "2023-10-18  22:12:54\n",
      "Epoch: 004, Train Acc: 0.7705\n",
      "2023-10-18  22:12:56\n",
      "Epoch: 005, Train Acc: 0.7705\n",
      "2023-10-18  22:12:58\n",
      "Epoch: 006, Train Acc: 0.7541\n",
      "2023-10-18  22:13:00\n",
      "Epoch: 007, Train Acc: 0.7869\n",
      "2023-10-18  22:13:02\n",
      "Epoch: 008, Train Acc: 0.7377\n",
      "2023-10-18  22:13:05\n",
      "Epoch: 009, Train Acc: 0.7541\n",
      "2023-10-18  22:13:07\n",
      "Epoch: 010, Train Acc: 0.7377\n",
      "2023-10-18  22:13:09\n",
      "Epoch: 011, Train Acc: 0.7377\n",
      "2023-10-18  22:13:11\n",
      "Epoch: 012, Train Acc: 0.7377\n",
      "2023-10-18  22:13:13\n",
      "Epoch: 013, Train Acc: 0.7541\n",
      "2023-10-18  22:13:15\n",
      "Epoch: 014, Train Acc: 0.7705\n",
      "2023-10-18  22:13:17\n",
      "Epoch: 015, Train Acc: 0.7541\n",
      "2023-10-18  22:13:19\n",
      "Epoch: 016, Train Acc: 0.7541\n",
      "2023-10-18  22:13:21\n",
      "Epoch: 017, Train Acc: 0.8197\n",
      "2023-10-18  22:13:23\n",
      "Epoch: 018, Train Acc: 0.7541\n",
      "2023-10-18  22:13:25\n",
      "Epoch: 019, Train Acc: 0.7541\n",
      "2023-10-18  22:13:27\n",
      "Epoch: 020, Train Acc: 0.7377\n",
      "2023-10-18  22:13:29\n",
      "Epoch: 021, Train Acc: 0.7377\n",
      "2023-10-18  22:13:31\n",
      "Epoch: 022, Train Acc: 0.7213\n",
      "2023-10-18  22:13:33\n",
      "Epoch: 023, Train Acc: 0.7541\n",
      "2023-10-18  22:13:35\n",
      "Epoch: 024, Train Acc: 0.7541\n",
      "2023-10-18  22:13:37\n",
      "Epoch: 025, Train Acc: 0.7705\n",
      "2023-10-18  22:13:38\n",
      "Epoch: 026, Train Acc: 0.7541\n",
      "2023-10-18  22:13:40\n",
      "Epoch: 027, Train Acc: 0.7541\n",
      "2023-10-18  22:13:42\n",
      "Epoch: 028, Train Acc: 0.7541\n",
      "2023-10-18  22:13:44\n",
      "Epoch: 029, Train Acc: 0.7705\n",
      "2023-10-18  22:13:46\n",
      "Epoch: 030, Train Acc: 0.7705\n",
      "2023-10-18  22:13:48\n",
      "Epoch: 031, Train Acc: 0.7377\n",
      "2023-10-18  22:13:50\n",
      "Epoch: 032, Train Acc: 0.7869\n",
      "2023-10-18  22:13:52\n",
      "Epoch: 033, Train Acc: 0.8033\n",
      "2023-10-18  22:13:54\n",
      "Epoch: 034, Train Acc: 0.7869\n",
      "2023-10-18  22:13:55\n",
      "Epoch: 035, Train Acc: 0.7869\n",
      "2023-10-18  22:13:57\n",
      "Epoch: 036, Train Acc: 0.7377\n",
      "2023-10-18  22:13:59\n",
      "Epoch: 037, Train Acc: 0.7869\n",
      "2023-10-18  22:14:01\n",
      "Epoch: 038, Train Acc: 0.7869\n",
      "2023-10-18  22:14:03\n",
      "Epoch: 039, Train Acc: 0.7705\n",
      "2023-10-18  22:14:05\n",
      "Epoch: 040, Train Acc: 0.7541\n",
      "2023-10-18  22:14:07\n",
      "Epoch: 041, Train Acc: 0.7541\n",
      "2023-10-18  22:14:09\n",
      "Epoch: 042, Train Acc: 0.8033\n",
      "2023-10-18  22:14:11\n",
      "Epoch: 043, Train Acc: 0.8197\n",
      "2023-10-18  22:14:12\n",
      "Epoch: 044, Train Acc: 0.7705\n",
      "2023-10-18  22:14:14\n",
      "Epoch: 045, Train Acc: 0.7705\n",
      "2023-10-18  22:14:16\n",
      "Epoch: 046, Train Acc: 0.7705\n",
      "2023-10-18  22:14:18\n",
      "Epoch: 047, Train Acc: 0.7705\n",
      "2023-10-18  22:14:20\n",
      "Epoch: 048, Train Acc: 0.8033\n",
      "2023-10-18  22:14:21\n",
      "Epoch: 049, Train Acc: 0.8033\n",
      "2023-10-18  22:14:23\n",
      "Epoch: 050, Train Acc: 0.7869\n",
      "2023-10-18  22:14:25\n",
      "Epoch: 051, Train Acc: 0.7705\n",
      "2023-10-18  22:14:27\n",
      "Epoch: 052, Train Acc: 0.8033\n",
      "2023-10-18  22:14:29\n",
      "Epoch: 053, Train Acc: 0.7869\n",
      "2023-10-18  22:14:30\n",
      "Epoch: 054, Train Acc: 0.8033\n",
      "2023-10-18  22:14:32\n",
      "Epoch: 055, Train Acc: 0.8197\n",
      "2023-10-18  22:14:34\n",
      "Epoch: 056, Train Acc: 0.7705\n",
      "2023-10-18  22:14:36\n",
      "Epoch: 057, Train Acc: 0.7869\n",
      "2023-10-18  22:14:38\n",
      "Epoch: 058, Train Acc: 0.7869\n",
      "2023-10-18  22:14:39\n",
      "Epoch: 059, Train Acc: 0.8033\n",
      "2023-10-18  22:14:41\n",
      "Epoch: 060, Train Acc: 0.8033\n",
      "2023-10-18  22:14:43\n",
      "Epoch: 061, Train Acc: 0.7705\n",
      "2023-10-18  22:14:45\n",
      "Epoch: 062, Train Acc: 0.7869\n",
      "2023-10-18  22:14:46\n",
      "Epoch: 063, Train Acc: 0.8197\n",
      "2023-10-18  22:14:48\n",
      "Epoch: 064, Train Acc: 0.8033\n",
      "2023-10-18  22:14:50\n",
      "Epoch: 065, Train Acc: 0.7705\n",
      "2023-10-18  22:14:52\n",
      "Epoch: 066, Train Acc: 0.7541\n",
      "2023-10-18  22:14:53\n",
      "Epoch: 067, Train Acc: 0.8033\n",
      "2023-10-18  22:14:55\n",
      "Epoch: 068, Train Acc: 0.8197\n",
      "2023-10-18  22:14:57\n",
      "Epoch: 069, Train Acc: 0.8197\n",
      "2023-10-18  22:14:59\n",
      "Epoch: 070, Train Acc: 0.8197\n",
      "2023-10-18  22:15:00\n",
      "Epoch: 071, Train Acc: 0.7869\n",
      "2023-10-18  22:15:02\n",
      "Epoch: 072, Train Acc: 0.7869\n",
      "2023-10-18  22:15:04\n",
      "Epoch: 073, Train Acc: 0.7377\n",
      "2023-10-18  22:15:06\n",
      "Epoch: 074, Train Acc: 0.7869\n",
      "2023-10-18  22:15:08\n",
      "Epoch: 075, Train Acc: 0.7869\n",
      "2023-10-18  22:15:10\n",
      "Epoch: 076, Train Acc: 0.8197\n",
      "2023-10-18  22:15:12\n",
      "Epoch: 077, Train Acc: 0.8197\n",
      "2023-10-18  22:15:13\n",
      "Epoch: 078, Train Acc: 0.7869\n",
      "2023-10-18  22:15:15\n",
      "Epoch: 079, Train Acc: 0.7869\n",
      "2023-10-18  22:15:17\n",
      "Epoch: 080, Train Acc: 0.7213\n",
      "2023-10-18  22:15:19\n",
      "Epoch: 081, Train Acc: 0.7049\n",
      "2023-10-18  22:15:21\n",
      "Epoch: 082, Train Acc: 0.7705\n",
      "2023-10-18  22:15:23\n",
      "Epoch: 083, Train Acc: 0.8033\n",
      "2023-10-18  22:15:24\n",
      "Epoch: 084, Train Acc: 0.7541\n",
      "2023-10-18  22:15:26\n",
      "Epoch: 085, Train Acc: 0.7705\n",
      "2023-10-18  22:15:28\n",
      "Epoch: 086, Train Acc: 0.7869\n",
      "2023-10-18  22:15:30\n",
      "Epoch: 087, Train Acc: 0.7705\n",
      "2023-10-18  22:15:31\n",
      "Epoch: 088, Train Acc: 0.8197\n",
      "2023-10-18  22:15:33\n",
      "Epoch: 089, Train Acc: 0.7869\n",
      "2023-10-18  22:15:35\n",
      "Epoch: 090, Train Acc: 0.7377\n",
      "2023-10-18  22:15:37\n",
      "Epoch: 091, Train Acc: 0.7705\n",
      "2023-10-18  22:15:38\n",
      "Epoch: 092, Train Acc: 0.7541\n",
      "2023-10-18  22:15:40\n",
      "Epoch: 093, Train Acc: 0.7541\n",
      "2023-10-18  22:15:42\n",
      "Epoch: 094, Train Acc: 0.7869\n",
      "2023-10-18  22:15:43\n",
      "Epoch: 095, Train Acc: 0.7541\n",
      "2023-10-18  22:15:45\n",
      "Epoch: 096, Train Acc: 0.7869\n",
      "2023-10-18  22:15:47\n",
      "Epoch: 097, Train Acc: 0.7213\n",
      "2023-10-18  22:15:49\n",
      "Epoch: 098, Train Acc: 0.7541\n",
      "2023-10-18  22:15:50\n",
      "Epoch: 099, Train Acc: 0.7869\n",
      "2023-10-18  22:15:52\n",
      "Epoch: 100, Train Acc: 0.7705\n",
      "2023-10-18  22:15:54\n",
      "Epoch: 101, Train Acc: 0.7705\n",
      "2023-10-18  22:15:56\n",
      "Epoch: 102, Train Acc: 0.7705\n",
      "2023-10-18  22:15:58\n",
      "Epoch: 103, Train Acc: 0.7705\n",
      "2023-10-18  22:15:59\n",
      "Epoch: 104, Train Acc: 0.7705\n",
      "2023-10-18  22:16:01\n",
      "Epoch: 105, Train Acc: 0.7705\n",
      "2023-10-18  22:16:03\n",
      "Epoch: 106, Train Acc: 0.7869\n",
      "2023-10-18  22:16:05\n",
      "Epoch: 107, Train Acc: 0.7705\n",
      "2023-10-18  22:16:07\n",
      "Epoch: 108, Train Acc: 0.7377\n",
      "2023-10-18  22:16:09\n",
      "Epoch: 109, Train Acc: 0.7705\n",
      "2023-10-18  22:16:11\n",
      "Epoch: 110, Train Acc: 0.7705\n",
      "2023-10-18  22:16:12\n",
      "Epoch: 111, Train Acc: 0.7705\n",
      "2023-10-18  22:16:14\n",
      "Epoch: 112, Train Acc: 0.7541\n",
      "2023-10-18  22:16:16\n",
      "Epoch: 113, Train Acc: 0.7541\n",
      "2023-10-18  22:16:18\n",
      "Epoch: 114, Train Acc: 0.7705\n",
      "2023-10-18  22:16:20\n",
      "Epoch: 115, Train Acc: 0.7541\n",
      "2023-10-18  22:16:22\n",
      "Epoch: 116, Train Acc: 0.7377\n",
      "2023-10-18  22:16:23\n",
      "Epoch: 117, Train Acc: 0.7869\n",
      "2023-10-18  22:16:25\n",
      "Epoch: 118, Train Acc: 0.8033\n",
      "2023-10-18  22:16:27\n",
      "Epoch: 119, Train Acc: 0.8361\n",
      "2023-10-18  22:16:29\n",
      "Epoch: 120, Train Acc: 0.8361\n",
      "2023-10-18  22:16:31\n",
      "Epoch: 121, Train Acc: 0.7377\n",
      "2023-10-18  22:16:33\n",
      "Epoch: 122, Train Acc: 0.7541\n",
      "2023-10-18  22:16:35\n",
      "Epoch: 123, Train Acc: 0.7541\n",
      "2023-10-18  22:16:36\n",
      "Epoch: 124, Train Acc: 0.7377\n",
      "2023-10-18  22:16:38\n",
      "Epoch: 125, Train Acc: 0.7213\n",
      "2023-10-18  22:16:40\n",
      "Epoch: 126, Train Acc: 0.7541\n",
      "2023-10-18  22:16:42\n",
      "Epoch: 127, Train Acc: 0.7705\n",
      "2023-10-18  22:16:44\n",
      "Epoch: 128, Train Acc: 0.7705\n",
      "2023-10-18  22:16:46\n",
      "Epoch: 129, Train Acc: 0.7705\n",
      "2023-10-18  22:16:48\n",
      "Epoch: 130, Train Acc: 0.7705\n",
      "2023-10-18  22:16:49\n",
      "Epoch: 131, Train Acc: 0.7869\n",
      "2023-10-18  22:16:51\n",
      "Epoch: 132, Train Acc: 0.7377\n",
      "2023-10-18  22:16:53\n",
      "Epoch: 133, Train Acc: 0.7541\n",
      "2023-10-18  22:16:55\n",
      "Epoch: 134, Train Acc: 0.7541\n",
      "2023-10-18  22:16:57\n",
      "Epoch: 135, Train Acc: 0.7541\n",
      "2023-10-18  22:16:59\n",
      "Epoch: 136, Train Acc: 0.7705\n",
      "2023-10-18  22:17:01\n",
      "Epoch: 137, Train Acc: 0.7869\n",
      "2023-10-18  22:17:02\n",
      "Epoch: 138, Train Acc: 0.7541\n",
      "2023-10-18  22:17:04\n",
      "Epoch: 139, Train Acc: 0.7705\n",
      "2023-10-18  22:17:06\n",
      "Epoch: 140, Train Acc: 0.7705\n",
      "2023-10-18  22:17:08\n",
      "Epoch: 141, Train Acc: 0.7705\n",
      "2023-10-18  22:17:09\n",
      "Epoch: 142, Train Acc: 0.7705\n",
      "2023-10-18  22:17:11\n",
      "Epoch: 143, Train Acc: 0.7705\n",
      "2023-10-18  22:17:13\n",
      "Epoch: 144, Train Acc: 0.7705\n",
      "2023-10-18  22:17:15\n",
      "Epoch: 145, Train Acc: 0.7377\n",
      "2023-10-18  22:17:17\n",
      "Epoch: 146, Train Acc: 0.7705\n",
      "2023-10-18  22:17:19\n",
      "Epoch: 147, Train Acc: 0.7705\n",
      "2023-10-18  22:17:20\n",
      "Epoch: 148, Train Acc: 0.7869\n",
      "2023-10-18  22:17:22\n",
      "Epoch: 149, Train Acc: 0.7541\n",
      "2023-10-18  22:17:24\n",
      "Epoch: 150, Train Acc: 0.7705\n",
      "2023-10-18  22:17:26\n",
      "Epoch: 151, Train Acc: 0.7705\n",
      "2023-10-18  22:17:28\n",
      "Epoch: 152, Train Acc: 0.7705\n",
      "2023-10-18  22:17:30\n",
      "Epoch: 153, Train Acc: 0.7869\n",
      "2023-10-18  22:17:32\n",
      "Epoch: 154, Train Acc: 0.7377\n",
      "2023-10-18  22:17:33\n",
      "Epoch: 155, Train Acc: 0.7705\n",
      "2023-10-18  22:17:35\n",
      "Epoch: 156, Train Acc: 0.8033\n",
      "2023-10-18  22:17:37\n",
      "Epoch: 157, Train Acc: 0.8197\n",
      "2023-10-18  22:17:39\n",
      "Epoch: 158, Train Acc: 0.7705\n",
      "2023-10-18  22:17:41\n",
      "Epoch: 159, Train Acc: 0.8033\n",
      "2023-10-18  22:17:43\n",
      "Epoch: 160, Train Acc: 0.8033\n",
      "2023-10-18  22:17:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161, Train Acc: 0.8197\n",
      "2023-10-18  22:17:46\n",
      "Epoch: 162, Train Acc: 0.7705\n",
      "2023-10-18  22:17:48\n",
      "Epoch: 163, Train Acc: 0.7869\n",
      "2023-10-18  22:17:50\n",
      "Epoch: 164, Train Acc: 0.8033\n",
      "2023-10-18  22:17:52\n",
      "Epoch: 165, Train Acc: 0.8033\n",
      "2023-10-18  22:17:53\n",
      "Epoch: 166, Train Acc: 0.7705\n",
      "2023-10-18  22:17:55\n",
      "Epoch: 167, Train Acc: 0.7705\n",
      "2023-10-18  22:17:57\n",
      "Epoch: 168, Train Acc: 0.7377\n",
      "2023-10-18  22:17:59\n",
      "Epoch: 169, Train Acc: 0.7541\n",
      "2023-10-18  22:18:00\n",
      "Epoch: 170, Train Acc: 0.7541\n",
      "2023-10-18  22:18:02\n",
      "Epoch: 171, Train Acc: 0.7377\n",
      "2023-10-18  22:18:04\n",
      "Epoch: 172, Train Acc: 0.7869\n",
      "2023-10-18  22:18:06\n",
      "Epoch: 173, Train Acc: 0.7705\n",
      "2023-10-18  22:18:08\n",
      "Epoch: 174, Train Acc: 0.7213\n",
      "2023-10-18  22:18:09\n",
      "Epoch: 175, Train Acc: 0.7705\n",
      "2023-10-18  22:18:11\n",
      "Epoch: 176, Train Acc: 0.7705\n",
      "2023-10-18  22:18:13\n",
      "Epoch: 177, Train Acc: 0.7541\n",
      "2023-10-18  22:18:15\n",
      "Epoch: 178, Train Acc: 0.7377\n",
      "2023-10-18  22:18:17\n",
      "Epoch: 179, Train Acc: 0.7541\n",
      "2023-10-18  22:18:18\n",
      "Epoch: 180, Train Acc: 0.7541\n",
      "2023-10-18  22:18:20\n",
      "Epoch: 181, Train Acc: 0.7541\n",
      "2023-10-18  22:18:22\n",
      "Epoch: 182, Train Acc: 0.7869\n",
      "2023-10-18  22:18:24\n",
      "Epoch: 183, Train Acc: 0.7705\n",
      "2023-10-18  22:18:26\n",
      "Epoch: 184, Train Acc: 0.7541\n",
      "2023-10-18  22:18:27\n",
      "Epoch: 185, Train Acc: 0.7705\n",
      "2023-10-18  22:18:29\n",
      "Epoch: 186, Train Acc: 0.7869\n",
      "2023-10-18  22:18:31\n",
      "Epoch: 187, Train Acc: 0.7541\n",
      "2023-10-18  22:18:33\n",
      "Epoch: 188, Train Acc: 0.7869\n",
      "2023-10-18  22:18:35\n",
      "Epoch: 189, Train Acc: 0.7705\n",
      "2023-10-18  22:18:36\n",
      "Epoch: 190, Train Acc: 0.7705\n",
      "2023-10-18  22:18:38\n",
      "Epoch: 191, Train Acc: 0.7541\n",
      "2023-10-18  22:18:40\n",
      "Epoch: 192, Train Acc: 0.8033\n",
      "2023-10-18  22:18:42\n",
      "Epoch: 193, Train Acc: 0.7869\n",
      "2023-10-18  22:18:44\n",
      "Epoch: 194, Train Acc: 0.7705\n",
      "2023-10-18  22:18:46\n",
      "Epoch: 195, Train Acc: 0.7541\n",
      "2023-10-18  22:18:47\n",
      "Epoch: 196, Train Acc: 0.8033\n",
      "2023-10-18  22:18:49\n",
      "Epoch: 197, Train Acc: 0.8033\n",
      "2023-10-18  22:18:51\n",
      "Epoch: 198, Train Acc: 0.8033\n",
      "2023-10-18  22:18:53\n",
      "Epoch: 199, Train Acc: 0.8197\n",
      "2023-10-18  22:18:55\n",
      "Epoch: 200, Train Acc: 0.7705\n"
     ]
    }
   ],
   "source": [
    "optimizer_tuning = torch.optim.AdamW(filter(lambda p: p.requires_grad, model_tuning.parameters()),lr=0.001)\n",
    "criterion_tuning = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_tuning()\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "    train_acc = test_tuning(bulk_total_loader)\n",
    "    #test_acc = test_tuning(TCGA_test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if (train_acc > 0.85):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_tuning.named_parameters(): print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8148779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tuning_subclass(loader):\n",
    "    model_tuning.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    label_correct = {}\n",
    "    total_label = {}\n",
    "    for k in range(3):\n",
    "        #print (type(k))\n",
    "        total_label[k] = 0\n",
    "        label_correct[k] = 0\n",
    "    #print (label_correct[10])\n",
    "    for data in loader:# 批遍历测试集数据集。\n",
    "        data = data.to(device)\n",
    "        out = model_tuning(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        total += int((pred == data.y).sum())\n",
    "        index = 0\n",
    "        for i in pred:\n",
    "            num = i.item()\n",
    "            #print (num)\n",
    "            #print (data.y[0].item())\n",
    "            total_label[data.y[index].item()] += 1\n",
    "            if (num == data.y[index].item()):\n",
    "                label_correct[num] += 1\n",
    "            index += 1\n",
    "    for j in total_label.keys():\n",
    "        correct_num = label_correct[j]\n",
    "        ratio = correct_num / total_label[j] if total_label[j] != 0 else 0\n",
    "        print (j,total_label[j],ratio)\n",
    "    return total / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = test_tuning_subclass(bulk_test_loader)\n",
    "#print (test_acc.)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(e_mask, dt):\n",
    "    #batch = torch.zeros(dt.x.shape[0], dtype=int).to(device)\n",
    "    batch = torch.zeros(dt.x.shape[0], dtype=int).to(device)\n",
    "    out = model_tuning(dt.x,\n",
    "                dt.edge_index,\n",
    "                batch,\n",
    "                e_mask)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(method, dt, target=0):\n",
    "    #input_mask = torch.ones(dt.edge_index.shape[1]).requires_grad_(True).to(device)\n",
    "    input_mask = torch.ones(dt.edge_index.shape[1]).requires_grad_(True)\n",
    "    if method == 'ig':\n",
    "        ig = IntegratedGradients(model_forward)\n",
    "        mask = ig.attribute(input_mask, target=target,\n",
    "                            additional_forward_args=(dt,),\n",
    "                            internal_batch_size=dt.edge_index.shape[1])\n",
    "    elif method == 'saliency':\n",
    "        saliency = Saliency(model_forward)\n",
    "        mask = saliency.attribute(input_mask, target=target,\n",
    "                                  additional_forward_args=(data,))\n",
    "    else:\n",
    "        raise Exception('Unknown explanation method')\n",
    " \n",
    "    edge_mask = np.abs(mask.cuda().detach().numpy())\n",
    "    if edge_mask.max() > 0:  # avoid division by zero\n",
    "        edge_mask = edge_mask / edge_mask.max()\n",
    "    return edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bulk_total_sets[10]\n",
    "print (data)\n",
    "data = data.to(device)\n",
    "target = 0\n",
    "target = torch.tensor(target).to(device)\n",
    "#import random\n",
    "#data = random.choice([t for t in bulk_test_sets if not t.y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_tuning, '/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/GSE16879.IBD.Response.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46316a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bulk_total_sets,\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/GSE16879.IBD.Response.data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a95d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_mask = explain(\"ig\", data, target=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fbb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_tissue in range(2):\n",
    "    title = 'Integrated Gradients'\n",
    "    method = 'ig'\n",
    "    #data.to(device)\n",
    "    #print(F\"processing tissue {target_tissue} with {title}, a.k.a. {method}\")\n",
    "    edge_mask = explain(method, data, target=target_tissue)\n",
    "    # edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "    #path = F\"/home/jgburk/PycharmProjects/reticula/data/SRP035988/output/{method}_{target_tissue}.txt\"\n",
    "    #numpy.savetxt(path, edge_mask, delimiter=\",\")\n",
    "    #print(F\"{method} {target_tissue} edges saved as {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6751cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_mask = torch.ones(data.edge_index.shape[1]).requires_grad_(True).to(device)\n",
    "input_mask = torch.ones(data.edge_index.shape[1]).requires_grad_(True)\n",
    "input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model_forward)\n",
    "ig.attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ig.attribute(input_mask, target=1,\n",
    "                            additional_forward_args=(data,),\n",
    "                            internal_batch_size=data.edge_index.shape[1])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39177687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "t_v = np.loadtxt(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/test.label\", dtype=str)\n",
    "t_v\n",
    "t_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "t_v = t_encoder.fit_transform(t_v)\n",
    "torch.tensor(t_v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = DataLoader(bulk_total_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54925d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data.edge_index.device)\n",
    "print (data.x.device)\n",
    "print (data.y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dataset[0].edge_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
