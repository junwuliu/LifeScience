{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b869079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Linear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0650294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53aa9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features,hidden_channels,num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels,num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch,edge_weight=None):\n",
    "        # 1. 获得节点嵌入\n",
    "        x = self.conv1(x, edge_index,edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index,edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index,edge_weight)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)   # [batch_size, hidden_channels]\n",
    "        \n",
    "        # 3. 分类器\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "329ee987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(1, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model_tuning = GNN(num_node_features=1,hidden_channels=64,num_classes=31).to(device)\n",
    "#checkpoint = torch.load('/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reaction.PCA_convEdgeWeight.1018.pt')\n",
    "model_tuning = torch.load(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reaction.PCA_convEdgeWeight.1018.pt\",map_location=device)\n",
    "#model_tuning.load_state_dict(checkpoint)\n",
    "model_tuning.lin = Linear(64,20)\n",
    "print (model_tuning)\n",
    "model_tuning = model_tuning.to(device)\n",
    "# 固定除线性层外的layer 参数\n",
    "for name,layer in model_tuning.named_parameters():\n",
    "    if (name == 'lin.weight' or (name == 'lin.bias')):\n",
    "        #print (name,layer)\n",
    "        layer.requires_grad = True\n",
    "    else:\n",
    "        layer.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_tuning.named_parameters(): print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcf4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bile duct': 0, 'Bladder': 1, 'Brain': 2, 'Breast': 3, 'Cervix Uteri': 4, 'Colorectal': 5, 'Esophagus': 6, 'Head and neck': 7, 'Kidney': 8, 'Liver': 9, 'Lung': 10, 'Muscle': 11, 'Nerve': 12, 'Pancreas': 13, 'Prostate': 14, 'Skin': 15, 'Stomach': 16, 'Thymus': 17, 'Thyroid': 18, 'Uterus': 19}\n"
     ]
    }
   ],
   "source": [
    "## 读取TCGA 样本对应的组织标签\n",
    "TCGA_sample_label = pd.read_csv('/public/home/liujunwu/workdir/scripts/GNN_Reactome/TCGA_exp/GSEA/TCGA_sample.label',header=None,sep=\",\")\n",
    "TCGA_sample_label.columns = ['Sample','short']\n",
    "TCGA_tissue_label = pd.read_csv('/public/home/liujunwu/workdir/scripts/GNN_Reactome/TCGA_exp/GSEA/TCGA_tissue.label',header=None,sep='\\t')\n",
    "TCGA_tissue_label.columns = ['short','long']\n",
    "TCGA_merge = pd.merge(left=TCGA_sample_label, \n",
    "                   right=TCGA_tissue_label, \n",
    "                   how='left', \n",
    "                   on='short')\n",
    "#print (TCGA_merge.iloc[0:3,0:3])\n",
    "TCGA_sample_label_dict = TCGA_merge[['Sample', \"long\"]].set_index(\"Sample\").to_dict(orient='dict')[\"long\"]\n",
    "#print (TCGA_sample_label_dict[\"TCGA-BT-A20R-11A-11R-A16R-07\"])\n",
    "TCGAsample_full_labels = sorted(list(set(TCGA_merge[\"long\"].tolist()))) ## 唯一值\n",
    "TCGAsample_full_labels_dict = dict(zip(TCGAsample_full_labels,range(len(TCGAsample_full_labels)))) ## label对应的index\n",
    "TCGAsample_full_labels_rev_dict = dict(zip(range(len(TCGAsample_full_labels)),TCGAsample_full_labels)) ## label对应的index\n",
    "TCGA_list_labels = []\n",
    "print (TCGAsample_full_labels_dict)\n",
    "for x in range(len(TCGAsample_full_labels)):\n",
    "    TCGA_list_labels.append([x])\n",
    "TCGA_list_labels_tensor = torch.tensor(TCGA_list_labels,dtype=torch.int64)\n",
    "#print (TCGA_list_labels[TCGAsample_full_labels_dict[TCGA_sample_label_dict[\"TCGA-BT-A20R-11A-11R-A16R-07\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9aaedcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGHV3-11,IGKV1D-33,SYK,SH3KBP1,IGHV1-69,IGLV1-47,IGKC,GRB2,IGHV2-70,IGLC7,IGKV3-11,IGHM,IGLV1-51,IGLV1-44,IGKV3-20,IGKV2D-28,IGKV2-30,NCK1,IGHV2-5,IGLC3,IGKV1-12,IGLV6-57,IGLV1-40,IGHD,IGKV2D-40,SOS1,IGLV3-25,IGHV3-23,IGHV1-2,IGLV2-14,IGKV2-28,IGKV1D-16,IGLV3-19,IGHV4-59,IGLV2-23,IGKV1D-12,IGHV3-33,IGLC1,BLNK,PLCG2,IGKV2D-30,IGLV3-27,IGKV3-15,IGLV2-11,IGHV3-48,IGHV3-9,BTK,IGLV2-8,IGKV1-17,IGKV3D-20,IGKV1-39,IGHV3-13,IGKV1-16,IGKV1D-39,IGHV4-34,IGKV2-29,IGLV7-43,IGLC6,IGKV4-1,IGLV3-1,IGKV5-2,CD79A,IGHV1-46,IGLV3-21,IGKV1-33,CD79B,IGKV1-5,IGHV4-39,VAV1,IGHV3-7,IGLC2,IGHV3-53,IGHV3-30\n"
     ]
    }
   ],
   "source": [
    "## 读取reaction包含的基因\n",
    "ReactionGeneFile = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.ProteinReactionNodes.txt\"\n",
    "ReactionGene = pd.read_csv(ReactionGeneFile,header=None,sep='\\t')\n",
    "ReactionGene.columns = [\"Reaction\",\"Gene\"]\n",
    "ReactionGene_dict = dict(zip(ReactionGene[\"Reaction\"],ReactionGene[\"Gene\"])) ## Reaction 对应的Gene\n",
    "print (ReactionGene_dict['R-HSA-1112666'])\n",
    "del ReactionGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8510a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.edges.txt\"\n",
    "edges = pd.read_csv(edges_file,header=None,sep=\"\\t\")\n",
    "edges.columns = [\"edge1\",\"edge2\",\"edge1_type\",\"edge2_type\"] \n",
    "uniq_output_nodes = sorted(list(set(edges[\"edge2\"].tolist()))) ## 取得唯一入度的点\n",
    "uniq_nodes = sorted(list(set(edges[\"edge1\"].tolist()) | set(edges[\"edge2\"].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368b84f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11573, 11462,     3,  ...,  6095,  9849,  9046],\n",
      "        [    0,     1,     2,  ..., 11713, 11713, 11713]])\n"
     ]
    }
   ],
   "source": [
    "edges = torch.load(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/Reactome_reaction_edges.pt\")\n",
    "print (edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980a7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "TCGA_expfile = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/TCGA_exp/all_TCGA.exp.csv\" ## 小数据集测试\n",
    "#GTEx_expfile = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GTEx_exp_down5000.csv\" ## 小数据集测试\n",
    "TCGA_exp = pd.read_csv(TCGA_expfile,header=0,sep=\",\")\n",
    "TCGA_genelist = TCGA_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a891b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLCA': 0, 'BRCA': 1, 'CESC': 2, 'CHOL': 3, 'COAD': 4, 'ESCA': 5, 'GBM': 6, 'HNSC': 7, 'KICH': 8, 'KIRC': 9, 'KIRP': 10, 'LIHC': 11, 'LUAD': 12, 'LUSC': 13, 'PAAD': 14, 'PCPG': 15, 'PRAD': 16, 'READ': 17, 'SARC': 18, 'SKCM': 19, 'STAD': 20, 'THCA': 21, 'THYM': 22, 'UCEC': 23}\n",
      "1\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "sample_full_labels = sorted(list(set(TCGA_exp[\"Label\"].tolist())))\n",
    "sample_full_labels_dict = dict(zip(sample_full_labels,range(len(sample_full_labels)))) ## label对应的index\n",
    "sample_index_dict = dict(zip(TCGA_exp[\"Sample\"],TCGA_exp.index)) \n",
    "list_labels = []\n",
    "print (sample_full_labels_dict)\n",
    "sample_dict = dict(zip(TCGA_exp[\"Sample\"],TCGA_exp[\"Label\"]))\n",
    "print (sample_full_labels_dict[sample_dict[\"TCGA-A7-A13G-11A-51R-A13Q-07\"]])\n",
    "for x in range(len(sample_full_labels)):\n",
    "    list_labels.append([x])\n",
    "list_labels_tensor = torch.tensor(list_labels,dtype=torch.int64)\n",
    "print (list_labels_tensor[sample_full_labels_dict[sample_dict[\"TCGA-A7-A13G-11A-51R-A13Q-07\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bcdd629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BLCA' 'BRCA' 'CESC' 'CHOL' 'COAD' 'ESCA' 'GBM' 'HNSC' 'KICH' 'KIRC'\n",
      " 'KIRP' 'LIHC' 'LUAD' 'LUSC' 'PAAD' 'PCPG' 'PRAD' 'READ' 'SARC' 'SKCM'\n",
      " 'STAD' 'THCA' 'THYM' 'UCEC']\n"
     ]
    }
   ],
   "source": [
    "TCGA_uniq_labels = TCGA_exp[\"Label\"].unique()\n",
    "print (TCGA_uniq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "209fb996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18  16:02:42\n",
      "2023-10-18  16:03:42\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.680701  1.081983  3.583182  3.583182 -0.426539 -0.327598 -0.339868   \n",
      "1  1.447236 -0.260758  3.589668  3.589668  0.537294  0.264704 -1.489758   \n",
      "2 -0.058676 -0.586946 -0.863641 -0.863641 -1.373529 -3.236777  2.921103   \n",
      "3  1.311051  0.148850  0.625590  0.625590  0.459675 -0.155701 -1.049457   \n",
      "4 -0.812770  0.956028  3.280487  3.280487  0.197606 -0.939456 -0.070037   \n",
      "5  1.700964  0.720706 -0.206392 -0.206392  0.635212  1.227438 -1.819872   \n",
      "6 -0.491500  1.055944  2.225275  2.225275 -0.103181  0.665602 -1.316430   \n",
      "7  0.576235 -0.161400  1.168823  1.168823 -1.917876 -3.758887  2.982174   \n",
      "8 -0.328893  0.760097  1.740886  1.740886 -0.856205 -1.337907  0.608190   \n",
      "9  1.292049  0.754481  1.939269  1.939269 -0.108517  0.989916 -1.459466   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.327598 -0.427571  0.547441  \n",
      "1  0.264704 -0.424239 -1.006817  \n",
      "2 -3.236777  1.560242 -0.699040  \n",
      "3 -0.155701 -1.137680 -1.325110  \n",
      "4 -0.939456 -0.154823  1.043918  \n",
      "5  1.227438 -1.535319 -0.818881  \n",
      "6  0.665602 -0.864485  1.180075  \n",
      "7 -3.758887  1.279285 -2.039284  \n",
      "8 -1.337907 -0.281048  3.796242  \n",
      "9  0.989916 -1.120454  0.938227  \n",
      "(730, 11714)\n"
     ]
    }
   ],
   "source": [
    "## 对于每一个reaction , PCA 得到的主成分 PCA1值\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## 对于每一个reaction , PCA 得到的主成分 PCA1值\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pca = PCA(n_components=2)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "sample_reaction_pca = pd.DataFrame()\n",
    "n = 0\n",
    "reaction_PCA_values = []\n",
    "for node in iter(uniq_nodes): ## 计算所有reaction节点 对应的PCA1 values\n",
    "    #print (node)\n",
    "    #node = \"R-HSA-1006169\"\n",
    "    if (node in ReactionGene_dict.keys()):\n",
    "        genelist = ReactionGene_dict[node].split(\",\")\n",
    "        common_gene = list(set(genelist) & set(TCGA_genelist))\n",
    "        ## 去除bulk中不存在的基因\n",
    "        sub_exp = TCGA_exp.loc[:,common_gene]\n",
    "        #print (sub_exp)\n",
    "        if (sub_exp.shape[1] >= 2):\n",
    "            #sub_exp = sub_exp.values\n",
    "            sub_exp = StandardScaler().fit_transform(sub_exp.values)\n",
    "            principalComponents = pca.fit_transform(sub_exp)\n",
    "            PCA_values =  pd.DataFrame(data = principalComponents,columns = [\"PCA1\",\"PCA2\"])\n",
    "            node_PCA_values = PCA_values[\"PCA1\"]\n",
    "        elif (sub_exp.shape[1] == 1): ## 如果reaction中只包含一个基因，无法做PCA，则对该基因表达量进行标准化\n",
    "            sub_exp = StandardScaler().fit_transform(sub_exp.values)\n",
    "            node_PCA_values = pd.DataFrame(data = sub_exp, columns=[\"PCA1\"])\n",
    "            #print (node_PCA_values)\n",
    "        else:\n",
    "            node_PCA_values = pd.DataFrame(np.zeros((TCGA_exp.shape[0],1)),columns=[\"PCA1\"])\n",
    "    else:\n",
    "        node_PCA_values = pd.DataFrame(np.zeros((TCGA_exp.shape[0],1)),columns=[\"PCA1\"])\n",
    "    reaction_PCA_values.append(node_PCA_values)\n",
    "    #sample_reaction_pca = pd.concat([sample_reaction_pca,node_PCA_values],axis=1,join='outer',ignore_index=True)\n",
    "    #n += 1\n",
    "    #if n >3:break\n",
    "    #break\n",
    "sample_reaction_pca = pd.concat(reaction_PCA_values,axis=1,join='outer',ignore_index=True)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "print (sample_reaction_pca.iloc[0:10,0:10])\n",
    "print (sample_reaction_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reaction_pca.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb3049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLCA 10\n",
      "BRCA 57\n",
      "CESC 2\n",
      "CHOL 5\n",
      "COAD 21\n",
      "ESCA 6\n",
      "GBM 3\n",
      "HNSC 22\n",
      "KICH 12\n",
      "KIRC 36\n",
      "KIRP 16\n",
      "LIHC 25\n",
      "LUAD 30\n",
      "LUSC 25\n",
      "PAAD 2\n",
      "PCPG 2\n",
      "PRAD 26\n",
      "READ 5\n",
      "SARC 1\n",
      "SKCM 1\n",
      "STAD 16\n",
      "THCA 29\n",
      "THYM 1\n",
      "UCEC 18\n",
      "371\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "## 根据TCGA不同组织，选取一半样本作为微调的训练集 \n",
    "TCGA_tuning_sets = []\n",
    "TCGA_test_sets = []\n",
    "for tissue in TCGA_uniq_labels:\n",
    "    TCGA_tissue_sample = TCGA_exp[TCGA_exp[\"Label\"] == tissue][\"Sample\"]\n",
    "    tuning_sample = TCGA_tissue_sample.sample(math.ceil(TCGA_tissue_sample.shape[0]/2)) ## 一半且向上取整\n",
    "    tuning_sample_index = tuning_sample.index\n",
    "    print (tissue,len(tuning_sample))\n",
    "    for m in tuning_sample:\n",
    "        sampleName = m\n",
    "        sample_index = sample_index_dict[sampleName]\n",
    "        sample_value = sample_reaction_pca.loc[sample_index].values\n",
    "        sample_value = sample_value.reshape(sample_value.shape[0],1)\n",
    "        sample_node_feature = Data(x=torch.tensor(sample_value,dtype = torch.float32),y=torch.tensor(TCGAsample_full_labels_dict[TCGA_sample_label_dict[sampleName]]),edge_index = edges)\n",
    "        TCGA_tuning_sets.append(sample_node_feature)\n",
    "        \n",
    "    test_sample = pd.concat([TCGA_tissue_sample,tuning_sample,tuning_sample]).drop_duplicates(keep=False)\n",
    "    for n in test_sample:\n",
    "        sampleName = n\n",
    "        sample_index = sample_index_dict[sampleName]\n",
    "        sample_value = sample_reaction_pca.loc[sample_index].values\n",
    "        sample_value = sample_value.reshape(sample_value.shape[0],1)\n",
    "        sample_node_feature = Data(x=torch.tensor(sample_value,dtype = torch.float32),y=torch.tensor(TCGAsample_full_labels_dict[TCGA_sample_label_dict[sampleName]]),edge_index = edges)\n",
    "        TCGA_test_sets.append(sample_node_feature)\n",
    "        \n",
    "print (len(TCGA_tuning_sets))\n",
    "print (len(TCGA_test_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ead60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_tuning():\n",
    "    model_tuning.train() ## \n",
    "    for data in TCGA_train_loader:\n",
    "        #print (data.y)\n",
    "        data = data.to(device)\n",
    "        optimizer_tuning.zero_grad()\n",
    "        out = model_tuning(data.x, data.edge_index,data.batch)\n",
    "        loss = criterion_tuning(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer_tuning.step()\n",
    "def test_tuning(loader):\n",
    "    model_tuning.eval()\n",
    "    correct = 0\n",
    "    for data in loader:                           # 批遍历测试集数据集。\n",
    "        data = data.to(device)\n",
    "        out = model_tuning(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        #print (pred,data.y)\n",
    "        correct += int((pred == data.y).sum())           # 检查真实标签\n",
    "    return correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee2d347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-18  20:52:16\n",
      "Epoch: 001, Train Acc: 0.0701\n",
      "Epoch: 002, Train Acc: 0.0916\n",
      "Epoch: 003, Train Acc: 0.1348\n",
      "Epoch: 004, Train Acc: 0.2210\n",
      "Epoch: 005, Train Acc: 0.2722\n",
      "Epoch: 006, Train Acc: 0.3046\n",
      "Epoch: 007, Train Acc: 0.3235\n",
      "Epoch: 008, Train Acc: 0.3504\n",
      "Epoch: 009, Train Acc: 0.3639\n",
      "Epoch: 010, Train Acc: 0.3747\n",
      "Epoch: 011, Train Acc: 0.3935\n",
      "Epoch: 012, Train Acc: 0.3989\n",
      "Epoch: 013, Train Acc: 0.4043\n",
      "Epoch: 014, Train Acc: 0.4124\n",
      "Epoch: 015, Train Acc: 0.4394\n",
      "Epoch: 016, Train Acc: 0.4528\n",
      "Epoch: 017, Train Acc: 0.4690\n",
      "Epoch: 018, Train Acc: 0.4933\n",
      "Epoch: 019, Train Acc: 0.5067\n",
      "Epoch: 020, Train Acc: 0.5202\n",
      "Epoch: 021, Train Acc: 0.5310\n",
      "Epoch: 022, Train Acc: 0.5391\n",
      "Epoch: 023, Train Acc: 0.5499\n",
      "Epoch: 024, Train Acc: 0.5580\n",
      "Epoch: 025, Train Acc: 0.5660\n",
      "Epoch: 026, Train Acc: 0.5795\n",
      "Epoch: 027, Train Acc: 0.5768\n",
      "Epoch: 028, Train Acc: 0.5822\n",
      "Epoch: 029, Train Acc: 0.5903\n",
      "Epoch: 030, Train Acc: 0.5984\n",
      "Epoch: 031, Train Acc: 0.6011\n",
      "Epoch: 032, Train Acc: 0.6092\n",
      "Epoch: 033, Train Acc: 0.6092\n",
      "Epoch: 034, Train Acc: 0.6173\n",
      "Epoch: 035, Train Acc: 0.6253\n",
      "Epoch: 036, Train Acc: 0.6307\n",
      "Epoch: 037, Train Acc: 0.6361\n",
      "Epoch: 038, Train Acc: 0.6523\n",
      "Epoch: 039, Train Acc: 0.6550\n",
      "Epoch: 040, Train Acc: 0.6577\n",
      "Epoch: 041, Train Acc: 0.6604\n",
      "Epoch: 042, Train Acc: 0.6631\n",
      "Epoch: 043, Train Acc: 0.6631\n",
      "Epoch: 044, Train Acc: 0.6631\n",
      "Epoch: 045, Train Acc: 0.6631\n",
      "Epoch: 046, Train Acc: 0.6658\n",
      "Epoch: 047, Train Acc: 0.6631\n",
      "Epoch: 048, Train Acc: 0.6631\n",
      "Epoch: 049, Train Acc: 0.6631\n",
      "Epoch: 050, Train Acc: 0.6631\n",
      "Epoch: 051, Train Acc: 0.6658\n",
      "Epoch: 052, Train Acc: 0.6712\n",
      "Epoch: 053, Train Acc: 0.6712\n",
      "Epoch: 054, Train Acc: 0.6712\n",
      "Epoch: 055, Train Acc: 0.6739\n",
      "Epoch: 056, Train Acc: 0.6739\n",
      "Epoch: 057, Train Acc: 0.6739\n",
      "Epoch: 058, Train Acc: 0.6792\n",
      "Epoch: 059, Train Acc: 0.6792\n",
      "Epoch: 060, Train Acc: 0.6819\n",
      "Epoch: 061, Train Acc: 0.6846\n",
      "Epoch: 062, Train Acc: 0.6846\n",
      "Epoch: 063, Train Acc: 0.6873\n",
      "Epoch: 064, Train Acc: 0.6873\n",
      "Epoch: 065, Train Acc: 0.6873\n",
      "Epoch: 066, Train Acc: 0.6927\n",
      "Epoch: 067, Train Acc: 0.6927\n",
      "Epoch: 068, Train Acc: 0.6927\n",
      "Epoch: 069, Train Acc: 0.6927\n",
      "Epoch: 070, Train Acc: 0.6954\n",
      "Epoch: 071, Train Acc: 0.6981\n",
      "Epoch: 072, Train Acc: 0.6981\n",
      "Epoch: 073, Train Acc: 0.6981\n",
      "Epoch: 074, Train Acc: 0.6981\n",
      "Epoch: 075, Train Acc: 0.6981\n",
      "Epoch: 076, Train Acc: 0.6981\n",
      "Epoch: 077, Train Acc: 0.7008\n",
      "Epoch: 078, Train Acc: 0.6981\n",
      "Epoch: 079, Train Acc: 0.7035\n",
      "Epoch: 080, Train Acc: 0.7062\n",
      "Epoch: 081, Train Acc: 0.7089\n",
      "Epoch: 082, Train Acc: 0.7035\n",
      "Epoch: 083, Train Acc: 0.7035\n",
      "Epoch: 084, Train Acc: 0.7062\n",
      "Epoch: 085, Train Acc: 0.7089\n",
      "Epoch: 086, Train Acc: 0.7089\n",
      "Epoch: 087, Train Acc: 0.7062\n",
      "Epoch: 088, Train Acc: 0.7089\n",
      "Epoch: 089, Train Acc: 0.7116\n",
      "Epoch: 090, Train Acc: 0.7116\n",
      "Epoch: 091, Train Acc: 0.7170\n",
      "Epoch: 092, Train Acc: 0.7089\n",
      "Epoch: 093, Train Acc: 0.7116\n",
      "Epoch: 094, Train Acc: 0.7170\n",
      "Epoch: 095, Train Acc: 0.7170\n",
      "Epoch: 096, Train Acc: 0.7170\n",
      "Epoch: 097, Train Acc: 0.7170\n",
      "Epoch: 098, Train Acc: 0.7170\n",
      "Epoch: 099, Train Acc: 0.7224\n",
      "Epoch: 100, Train Acc: 0.7305\n",
      "Epoch: 101, Train Acc: 0.7332\n",
      "Epoch: 102, Train Acc: 0.7332\n",
      "Epoch: 103, Train Acc: 0.7332\n",
      "Epoch: 104, Train Acc: 0.7332\n",
      "Epoch: 105, Train Acc: 0.7412\n",
      "Epoch: 106, Train Acc: 0.7385\n",
      "Epoch: 107, Train Acc: 0.7412\n",
      "Epoch: 108, Train Acc: 0.7412\n",
      "Epoch: 109, Train Acc: 0.7412\n",
      "Epoch: 110, Train Acc: 0.7385\n",
      "Epoch: 111, Train Acc: 0.7385\n",
      "Epoch: 112, Train Acc: 0.7439\n",
      "Epoch: 113, Train Acc: 0.7385\n",
      "Epoch: 114, Train Acc: 0.7412\n",
      "Epoch: 115, Train Acc: 0.7358\n",
      "Epoch: 116, Train Acc: 0.7412\n",
      "Epoch: 117, Train Acc: 0.7412\n",
      "Epoch: 118, Train Acc: 0.7439\n",
      "Epoch: 119, Train Acc: 0.7412\n",
      "Epoch: 120, Train Acc: 0.7439\n",
      "Epoch: 121, Train Acc: 0.7466\n",
      "Epoch: 122, Train Acc: 0.7466\n",
      "Epoch: 123, Train Acc: 0.7466\n",
      "Epoch: 124, Train Acc: 0.7493\n",
      "Epoch: 125, Train Acc: 0.7520\n",
      "Epoch: 126, Train Acc: 0.7520\n",
      "Epoch: 127, Train Acc: 0.7520\n",
      "Epoch: 128, Train Acc: 0.7547\n",
      "Epoch: 129, Train Acc: 0.7547\n",
      "Epoch: 130, Train Acc: 0.7547\n",
      "Epoch: 131, Train Acc: 0.7547\n",
      "Epoch: 132, Train Acc: 0.7547\n",
      "Epoch: 133, Train Acc: 0.7547\n",
      "Epoch: 134, Train Acc: 0.7547\n",
      "Epoch: 135, Train Acc: 0.7520\n",
      "Epoch: 136, Train Acc: 0.7601\n",
      "Epoch: 137, Train Acc: 0.7574\n",
      "Epoch: 138, Train Acc: 0.7547\n",
      "Epoch: 139, Train Acc: 0.7574\n",
      "Epoch: 140, Train Acc: 0.7601\n",
      "Epoch: 141, Train Acc: 0.7574\n",
      "Epoch: 142, Train Acc: 0.7574\n",
      "Epoch: 143, Train Acc: 0.7628\n",
      "Epoch: 144, Train Acc: 0.7601\n",
      "Epoch: 145, Train Acc: 0.7628\n",
      "Epoch: 146, Train Acc: 0.7655\n",
      "Epoch: 147, Train Acc: 0.7628\n",
      "Epoch: 148, Train Acc: 0.7655\n",
      "Epoch: 149, Train Acc: 0.7628\n",
      "Epoch: 150, Train Acc: 0.7601\n",
      "Epoch: 151, Train Acc: 0.7628\n",
      "Epoch: 152, Train Acc: 0.7628\n",
      "Epoch: 153, Train Acc: 0.7628\n",
      "Epoch: 154, Train Acc: 0.7628\n",
      "Epoch: 155, Train Acc: 0.7628\n",
      "Epoch: 156, Train Acc: 0.7601\n",
      "Epoch: 157, Train Acc: 0.7628\n",
      "Epoch: 158, Train Acc: 0.7628\n",
      "Epoch: 159, Train Acc: 0.7655\n",
      "Epoch: 160, Train Acc: 0.7682\n",
      "Epoch: 161, Train Acc: 0.7682\n",
      "Epoch: 162, Train Acc: 0.7682\n",
      "Epoch: 163, Train Acc: 0.7709\n",
      "Epoch: 164, Train Acc: 0.7682\n",
      "Epoch: 165, Train Acc: 0.7682\n",
      "Epoch: 166, Train Acc: 0.7682\n",
      "Epoch: 167, Train Acc: 0.7682\n",
      "Epoch: 168, Train Acc: 0.7682\n",
      "Epoch: 169, Train Acc: 0.7736\n",
      "Epoch: 170, Train Acc: 0.7736\n",
      "Epoch: 171, Train Acc: 0.7736\n",
      "Epoch: 172, Train Acc: 0.7709\n",
      "Epoch: 173, Train Acc: 0.7736\n",
      "Epoch: 174, Train Acc: 0.7736\n",
      "Epoch: 175, Train Acc: 0.7736\n",
      "Epoch: 176, Train Acc: 0.7736\n",
      "Epoch: 177, Train Acc: 0.7736\n",
      "Epoch: 178, Train Acc: 0.7736\n",
      "Epoch: 179, Train Acc: 0.7736\n",
      "Epoch: 180, Train Acc: 0.7736\n",
      "Epoch: 181, Train Acc: 0.7763\n",
      "Epoch: 182, Train Acc: 0.7763\n",
      "Epoch: 183, Train Acc: 0.7763\n",
      "Epoch: 184, Train Acc: 0.7736\n",
      "Epoch: 185, Train Acc: 0.7790\n",
      "Epoch: 186, Train Acc: 0.7844\n",
      "Epoch: 187, Train Acc: 0.7871\n",
      "Epoch: 188, Train Acc: 0.7844\n",
      "Epoch: 189, Train Acc: 0.7844\n",
      "Epoch: 190, Train Acc: 0.7871\n",
      "Epoch: 191, Train Acc: 0.7844\n",
      "Epoch: 192, Train Acc: 0.7871\n",
      "Epoch: 193, Train Acc: 0.7844\n",
      "Epoch: 194, Train Acc: 0.7817\n",
      "Epoch: 195, Train Acc: 0.7844\n",
      "Epoch: 196, Train Acc: 0.7844\n",
      "Epoch: 197, Train Acc: 0.7817\n",
      "Epoch: 198, Train Acc: 0.7817\n",
      "Epoch: 199, Train Acc: 0.7817\n",
      "Epoch: 200, Train Acc: 0.7817\n",
      "Epoch: 201, Train Acc: 0.7844\n",
      "Epoch: 202, Train Acc: 0.7844\n",
      "Epoch: 203, Train Acc: 0.7871\n",
      "Epoch: 204, Train Acc: 0.7898\n",
      "Epoch: 205, Train Acc: 0.7844\n",
      "Epoch: 206, Train Acc: 0.7871\n",
      "Epoch: 207, Train Acc: 0.7844\n",
      "Epoch: 208, Train Acc: 0.7871\n",
      "Epoch: 209, Train Acc: 0.7871\n",
      "Epoch: 210, Train Acc: 0.7871\n",
      "Epoch: 211, Train Acc: 0.7871\n",
      "Epoch: 212, Train Acc: 0.7871\n",
      "Epoch: 213, Train Acc: 0.7871\n",
      "Epoch: 214, Train Acc: 0.7871\n",
      "Epoch: 215, Train Acc: 0.7844\n",
      "Epoch: 216, Train Acc: 0.7844\n",
      "Epoch: 217, Train Acc: 0.7844\n",
      "Epoch: 218, Train Acc: 0.7871\n",
      "Epoch: 219, Train Acc: 0.7871\n",
      "Epoch: 220, Train Acc: 0.7871\n",
      "Epoch: 221, Train Acc: 0.7871\n",
      "Epoch: 222, Train Acc: 0.7871\n",
      "Epoch: 223, Train Acc: 0.7898\n",
      "Epoch: 224, Train Acc: 0.7898\n",
      "Epoch: 225, Train Acc: 0.7871\n",
      "Epoch: 226, Train Acc: 0.7871\n",
      "Epoch: 227, Train Acc: 0.7898\n",
      "Epoch: 228, Train Acc: 0.7871\n",
      "Epoch: 229, Train Acc: 0.7898\n",
      "Epoch: 230, Train Acc: 0.7925\n",
      "Epoch: 231, Train Acc: 0.7925\n",
      "Epoch: 232, Train Acc: 0.7925\n",
      "Epoch: 233, Train Acc: 0.7925\n",
      "Epoch: 234, Train Acc: 0.7925\n",
      "Epoch: 235, Train Acc: 0.7951\n",
      "Epoch: 236, Train Acc: 0.7925\n",
      "Epoch: 237, Train Acc: 0.7925\n",
      "Epoch: 238, Train Acc: 0.7925\n",
      "Epoch: 239, Train Acc: 0.7925\n",
      "Epoch: 240, Train Acc: 0.7925\n",
      "Epoch: 241, Train Acc: 0.7925\n",
      "Epoch: 242, Train Acc: 0.7925\n",
      "Epoch: 243, Train Acc: 0.7925\n",
      "Epoch: 244, Train Acc: 0.7925\n",
      "Epoch: 245, Train Acc: 0.7925\n",
      "Epoch: 246, Train Acc: 0.7951\n",
      "Epoch: 247, Train Acc: 0.7951\n",
      "Epoch: 248, Train Acc: 0.7951\n",
      "Epoch: 249, Train Acc: 0.7951\n",
      "Epoch: 250, Train Acc: 0.7978\n",
      "Epoch: 251, Train Acc: 0.7978\n",
      "Epoch: 252, Train Acc: 0.7978\n",
      "Epoch: 253, Train Acc: 0.7978\n",
      "Epoch: 254, Train Acc: 0.7978\n",
      "Epoch: 255, Train Acc: 0.8005\n",
      "Epoch: 256, Train Acc: 0.7978\n",
      "Epoch: 257, Train Acc: 0.8005\n",
      "Epoch: 258, Train Acc: 0.8005\n",
      "Epoch: 259, Train Acc: 0.8005\n",
      "Epoch: 260, Train Acc: 0.8005\n",
      "Epoch: 261, Train Acc: 0.8005\n",
      "Epoch: 262, Train Acc: 0.8005\n",
      "Epoch: 263, Train Acc: 0.8005\n",
      "Epoch: 264, Train Acc: 0.8032\n",
      "Epoch: 265, Train Acc: 0.8032\n",
      "Epoch: 266, Train Acc: 0.8032\n",
      "Epoch: 267, Train Acc: 0.8032\n",
      "Epoch: 268, Train Acc: 0.8032\n",
      "Epoch: 269, Train Acc: 0.8032\n",
      "Epoch: 270, Train Acc: 0.8032\n",
      "Epoch: 271, Train Acc: 0.8032\n",
      "Epoch: 272, Train Acc: 0.8032\n",
      "Epoch: 273, Train Acc: 0.8032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 274, Train Acc: 0.8059\n",
      "Epoch: 275, Train Acc: 0.8059\n",
      "Epoch: 276, Train Acc: 0.8032\n",
      "Epoch: 277, Train Acc: 0.8032\n",
      "Epoch: 278, Train Acc: 0.8032\n",
      "Epoch: 279, Train Acc: 0.8032\n",
      "Epoch: 280, Train Acc: 0.8032\n",
      "Epoch: 281, Train Acc: 0.8032\n",
      "Epoch: 282, Train Acc: 0.8032\n",
      "Epoch: 283, Train Acc: 0.8059\n",
      "Epoch: 284, Train Acc: 0.8032\n",
      "Epoch: 285, Train Acc: 0.8032\n",
      "Epoch: 286, Train Acc: 0.8059\n",
      "Epoch: 287, Train Acc: 0.8059\n",
      "Epoch: 288, Train Acc: 0.8059\n",
      "Epoch: 289, Train Acc: 0.8059\n",
      "Epoch: 290, Train Acc: 0.8059\n",
      "Epoch: 291, Train Acc: 0.8032\n",
      "Epoch: 292, Train Acc: 0.8032\n",
      "Epoch: 293, Train Acc: 0.8059\n",
      "Epoch: 294, Train Acc: 0.8059\n",
      "Epoch: 295, Train Acc: 0.8059\n",
      "Epoch: 296, Train Acc: 0.8059\n",
      "Epoch: 297, Train Acc: 0.8059\n",
      "Epoch: 298, Train Acc: 0.8059\n",
      "Epoch: 299, Train Acc: 0.8059\n",
      "Epoch: 300, Train Acc: 0.8059\n",
      "Epoch: 301, Train Acc: 0.8032\n",
      "Epoch: 302, Train Acc: 0.8032\n",
      "Epoch: 303, Train Acc: 0.8032\n",
      "Epoch: 304, Train Acc: 0.8032\n",
      "Epoch: 305, Train Acc: 0.8032\n",
      "Epoch: 306, Train Acc: 0.8032\n",
      "Epoch: 307, Train Acc: 0.8032\n",
      "Epoch: 308, Train Acc: 0.8032\n",
      "Epoch: 309, Train Acc: 0.8032\n",
      "Epoch: 310, Train Acc: 0.8032\n",
      "Epoch: 311, Train Acc: 0.8032\n",
      "Epoch: 312, Train Acc: 0.8032\n",
      "Epoch: 313, Train Acc: 0.8032\n",
      "Epoch: 314, Train Acc: 0.8032\n",
      "Epoch: 315, Train Acc: 0.8032\n",
      "Epoch: 316, Train Acc: 0.8059\n",
      "Epoch: 317, Train Acc: 0.8059\n",
      "Epoch: 318, Train Acc: 0.8059\n",
      "Epoch: 319, Train Acc: 0.8059\n",
      "Epoch: 320, Train Acc: 0.8032\n",
      "Epoch: 321, Train Acc: 0.8032\n",
      "Epoch: 322, Train Acc: 0.8032\n",
      "Epoch: 323, Train Acc: 0.8032\n",
      "Epoch: 324, Train Acc: 0.8059\n",
      "Epoch: 325, Train Acc: 0.8032\n",
      "Epoch: 326, Train Acc: 0.8059\n",
      "Epoch: 327, Train Acc: 0.8086\n",
      "Epoch: 328, Train Acc: 0.8086\n",
      "Epoch: 329, Train Acc: 0.8059\n",
      "Epoch: 330, Train Acc: 0.8086\n",
      "Epoch: 331, Train Acc: 0.8059\n",
      "Epoch: 332, Train Acc: 0.8059\n",
      "Epoch: 333, Train Acc: 0.8059\n",
      "Epoch: 334, Train Acc: 0.8059\n",
      "Epoch: 335, Train Acc: 0.8059\n",
      "Epoch: 336, Train Acc: 0.8059\n",
      "Epoch: 337, Train Acc: 0.8086\n",
      "Epoch: 338, Train Acc: 0.8086\n",
      "Epoch: 339, Train Acc: 0.8059\n",
      "Epoch: 340, Train Acc: 0.8086\n",
      "Epoch: 341, Train Acc: 0.8086\n",
      "Epoch: 342, Train Acc: 0.8086\n",
      "Epoch: 343, Train Acc: 0.8086\n",
      "Epoch: 344, Train Acc: 0.8086\n",
      "Epoch: 345, Train Acc: 0.8140\n",
      "Epoch: 346, Train Acc: 0.8113\n",
      "Epoch: 347, Train Acc: 0.8113\n",
      "Epoch: 348, Train Acc: 0.8140\n",
      "Epoch: 349, Train Acc: 0.8140\n",
      "Epoch: 350, Train Acc: 0.8140\n",
      "Epoch: 351, Train Acc: 0.8140\n",
      "Epoch: 352, Train Acc: 0.8086\n",
      "Epoch: 353, Train Acc: 0.8140\n",
      "Epoch: 354, Train Acc: 0.8140\n",
      "Epoch: 355, Train Acc: 0.8140\n",
      "Epoch: 356, Train Acc: 0.8140\n",
      "Epoch: 357, Train Acc: 0.8140\n",
      "Epoch: 358, Train Acc: 0.8086\n",
      "Epoch: 359, Train Acc: 0.8140\n",
      "Epoch: 360, Train Acc: 0.8140\n",
      "Epoch: 361, Train Acc: 0.8113\n",
      "Epoch: 362, Train Acc: 0.8113\n",
      "Epoch: 363, Train Acc: 0.8086\n",
      "Epoch: 364, Train Acc: 0.8113\n",
      "Epoch: 365, Train Acc: 0.8113\n",
      "Epoch: 366, Train Acc: 0.8086\n",
      "Epoch: 367, Train Acc: 0.8113\n",
      "Epoch: 368, Train Acc: 0.8113\n",
      "Epoch: 369, Train Acc: 0.8113\n",
      "Epoch: 370, Train Acc: 0.8113\n",
      "Epoch: 371, Train Acc: 0.8140\n",
      "Epoch: 372, Train Acc: 0.8113\n",
      "Epoch: 373, Train Acc: 0.8086\n",
      "Epoch: 374, Train Acc: 0.8086\n",
      "Epoch: 375, Train Acc: 0.8113\n",
      "Epoch: 376, Train Acc: 0.8113\n",
      "Epoch: 377, Train Acc: 0.8086\n",
      "Epoch: 378, Train Acc: 0.8113\n",
      "Epoch: 379, Train Acc: 0.8113\n",
      "Epoch: 380, Train Acc: 0.8113\n",
      "Epoch: 381, Train Acc: 0.8113\n",
      "Epoch: 382, Train Acc: 0.8086\n",
      "Epoch: 383, Train Acc: 0.8086\n",
      "Epoch: 384, Train Acc: 0.8086\n",
      "Epoch: 385, Train Acc: 0.8113\n",
      "Epoch: 386, Train Acc: 0.8086\n",
      "Epoch: 387, Train Acc: 0.8113\n",
      "Epoch: 388, Train Acc: 0.8059\n",
      "Epoch: 389, Train Acc: 0.8086\n",
      "Epoch: 390, Train Acc: 0.8086\n",
      "Epoch: 391, Train Acc: 0.8113\n",
      "Epoch: 392, Train Acc: 0.8113\n",
      "Epoch: 393, Train Acc: 0.8113\n",
      "Epoch: 394, Train Acc: 0.8113\n",
      "Epoch: 395, Train Acc: 0.8086\n",
      "Epoch: 396, Train Acc: 0.8086\n",
      "Epoch: 397, Train Acc: 0.8086\n",
      "Epoch: 398, Train Acc: 0.8086\n",
      "Epoch: 399, Train Acc: 0.8086\n",
      "Epoch: 400, Train Acc: 0.8113\n"
     ]
    }
   ],
   "source": [
    "TCGA_train_loader =  DataLoader(TCGA_tuning_sets, batch_size=5,shuffle=True)\n",
    "TCGA_test_loader = DataLoader(TCGA_test_sets, batch_size=5,shuffle=True)\n",
    "optimizer_tuning = torch.optim.Adam(model_tuning.parameters(), lr=1e-4)\n",
    "criterion_tuning = torch.nn.CrossEntropyLoss()\n",
    "#model_tuning.train()\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "\n",
    "from tqdm import *\n",
    "for epoch in range(1, 401):\n",
    "    train_tuning()\n",
    "    #print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "    train_acc = test_tuning(TCGA_train_loader)\n",
    "    #test_acc = test_tuning(TCGA_test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3caf4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tuning_subclass(loader):\n",
    "    model_tuning.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    label_correct = {}\n",
    "    total_label = {}\n",
    "    for k in range(20):\n",
    "        #print (type(k))\n",
    "        total_label[k] = 0\n",
    "        label_correct[k] = 0\n",
    "    #print (label_correct[10])\n",
    "    for data in loader:# 批遍历测试集数据集。\n",
    "        data = data.to(device)\n",
    "        out = model_tuning(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        total += int((pred == data.y).sum())\n",
    "        index = 0\n",
    "        for i in pred:\n",
    "            num = i.item()\n",
    "            #print (num)\n",
    "            #print (data.y[0].item())\n",
    "            total_label[data.y[index].item()] += 1\n",
    "            if (num == data.y[index].item()):\n",
    "                label_correct[num] += 1\n",
    "            index += 1\n",
    "    for j in total_label.keys():\n",
    "        correct_num = label_correct[j]\n",
    "        ratio = correct_num / total_label[j] if total_label[j] != 0 else 0\n",
    "        print (TCGAsample_full_labels_rev_dict[j],total_label[j],ratio)\n",
    "    return total / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cdc9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bile duct 4 0.0\n",
      "Bladder 9 0.1111111111111111\n",
      "Brain 2 1.0\n",
      "Breast 56 0.9464285714285714\n",
      "Cervix Uteri 1 0.0\n",
      "Colorectal 25 0.84\n",
      "Esophagus 5 0.6\n",
      "Head and neck 22 0.5909090909090909\n",
      "Kidney 64 0.9375\n",
      "Liver 25 1.0\n",
      "Lung 53 0.9056603773584906\n",
      "Muscle 1 0.0\n",
      "Nerve 1 1.0\n",
      "Pancreas 2 0.0\n",
      "Prostate 26 0.5384615384615384\n",
      "Skin 0 0\n",
      "Stomach 16 0.5\n",
      "Thymus 1 0.0\n",
      "Thyroid 29 0.8620689655172413\n",
      "Uterus 17 0.7058823529411765\n",
      "Test Acc: 0.7967\n"
     ]
    }
   ],
   "source": [
    "test_acc = test_tuning_subclass(TCGA_test_loader)\n",
    "#print (test_acc.)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ce631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
