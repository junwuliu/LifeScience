{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db31fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9e8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换成onehot\n",
    "def encode_onehot(labels):                                   \n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int64)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818e12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):                                          # 归一化\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten() ## 幂\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv) # 对角化\n",
    "    mx = r_mat_inv.dot(mx) # 乘积\n",
    "    #mx = mx * 10000\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 获得稳定的Tissue标签对应的数字\n",
    "GTEx_exp_full = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GTEx_exp_down3000.csv\",sep=',',header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (GTEx_exp_full.iloc[0:3,0:3])\n",
    "sample_full_labels = sorted(list(set(GTEx_exp_full[\"SMTS\"].tolist())))\n",
    "sample_full_labels_dict = dict(zip(sample_full_labels,range(len(sample_full_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e084e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (list(set(GTEx_exp_full[\"Tissue\"])))\n",
    "sample_full_labels = sorted(list(set(GTEx_exp_full[\"Tissue\"].tolist())))\n",
    "sample_full_labels_dict = dict(zip(sample_full_labels,range(len(sample_full_labels))))\n",
    "print (sample_full_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2633d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: 'Adipose Tissue', 7: 'Muscle', 4: 'Blood Vessel', 21: 'Heart', 18: 'Uterus', 14: 'Vagina', 6: 'Breast', 9: 'Skin', 20: 'Salivary Gland', 16: 'Brain', 8: 'Adrenal Gland', 11: 'Thyroid', 3: 'Lung', 10: 'Spleen', 5: 'Pancreas', 0: 'Esophagus', 15: 'Stomach', 19: 'Colon', 1: 'Small Intestine', 17: 'Prostate', 2: 'Testis', 12: 'Nerve'}\n",
      "Muscle\n",
      "torch.int64\n",
      "tensor([13])\n",
      "torch.Size([1])\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# 读取GTEx 表达谱文件\n",
    "GTEx_exp = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GTEx_exp.csv.test\",sep=',',header=0)\n",
    "sample_labels = np.where(encode_onehot(GTEx_exp[\"Tissue\"]))[1]\n",
    "#sample_labels = encode_onehot(GTEx_exp[\"Tissue\"])\n",
    "#print (sample_labels)\n",
    "# 存储标签和真实tissue关系\n",
    "sample_labels_dict = dict(zip(sample_labels,GTEx_exp[\"Tissue\"]))\n",
    "print (sample_labels_dict)\n",
    "print (sample_labels_dict[7])\n",
    "list_labels = []\n",
    "for x in list(sample_labels):\n",
    "    list_labels.append([x])\n",
    "sample_labels = torch.tensor(list_labels,dtype=torch.int64)\n",
    "#print (sample_labels)\n",
    "print (sample_labels.dtype)\n",
    "print (sample_labels[0])\n",
    "print (sample_labels[0].shape)\n",
    "print (len(sample_labels_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d28e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13590, 3)\n",
      "(13590, 7979)\n",
      "        Reaction             Type  Gene\n",
      "0  R-HSA-5336466  ProteinReaction  MRS2\n",
      "1  R-HSA-5216072     EwasReaction   NaN\n",
      "2  R-HSA-5226964  ProteinReaction  ANKH\n",
      "   A1CF  A2M  A4GNT\n",
      "0   0.0  0.0    0.0\n",
      "1   0.0  0.0    0.0\n",
      "2   0.0  0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "reaction_nodes = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.nodes.txt\",sep='\\t',header=None)\n",
    "print (reaction_nodes.shape)\n",
    "reaction_nodes.columns = [\"Reaction\",\"Type\",\"Gene\"]\n",
    "reaction_gene_list = []\n",
    "for index,row in reaction_nodes.iterrows():\n",
    "    if row[2] != \"\" :\n",
    "        reaction_gene_list.extend(str(row[2]).split(\",\"))\n",
    "common_gene_list = sorted(list(set(reaction_gene_list) & set(GTEx_exp.columns)))\n",
    "common_gene_list_dict = dict(zip(sorted(common_gene_list),range(len(common_gene_list))))\n",
    "#存储节点和index关系\n",
    "reaction_nodes_dict = dict(zip(reaction_nodes.index,reaction_nodes[\"Reaction\"]))\n",
    "reaction_nodes_rev_dict = dict(zip(reaction_nodes[\"Reaction\"],reaction_nodes.index))\n",
    "## 初始化0矩阵\n",
    "zero_matrix = pd.DataFrame(np.zeros((reaction_nodes.shape[0],len(common_gene_list))),columns = common_gene_list) \n",
    "print (zero_matrix.shape)\n",
    "print (reaction_nodes.iloc[0:3,0:3])\n",
    "print (zero_matrix.iloc[0:3,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14bc6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7979)\n"
     ]
    }
   ],
   "source": [
    "# 精简 GTEx_exp 的维度\n",
    "GTEx_exp_match = GTEx_exp.loc[:,list(common_gene_list)]\n",
    "print (GTEx_exp_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eec1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (\"SLC66A1\" in GTEx_exp_match.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06f08846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Edge1_index  Edge2_index\n",
      "0           13083        13084\n",
      "1           13098        13099\n",
      "2           11061        11062\n",
      "3           11063        11062\n",
      "4           11066        11067\n",
      "...           ...          ...\n",
      "8508         6791         5715\n",
      "8509         6792         4907\n",
      "8510         6789         6790\n",
      "8511        13068        13069\n",
      "8512         3702         3703\n",
      "\n",
      "[8513 rows x 2 columns]\n",
      "tensor([[13083, 13098, 11061,  ...,  6789, 13068,  3702],\n",
      "        [13084, 13099, 11062,  ...,  6790, 13069,  3703]])\n"
     ]
    }
   ],
   "source": [
    "edges_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.edges.uniq.txt\"\n",
    "edges_pd = pd.read_csv(edges_file,header=None,sep='\\t')\n",
    "#edges_pd.columns = [\"Edge1\",\"Edge2\",\"Type\",\"TopLevel\"]\n",
    "edges_pd.columns = [\"Edge1\",\"Edge2\"]\n",
    "edges_pd[\"Edge1_index\"] = edges_pd[\"Edge1\"].apply(lambda x : reaction_nodes_rev_dict[x])\n",
    "edges_pd[\"Edge2_index\"] = edges_pd[\"Edge2\"].apply(lambda x : reaction_nodes_rev_dict[x])\n",
    "#edges_trans.loc[df[\"Edge2\"]] = edges_trans[\"Edge2\"].apply(lambda x : reaction_nodes_dict[x])\n",
    "print (edges_pd[[\"Edge1_index\",\"Edge2_index\"]])\n",
    "edges_trans = edges_pd[[\"Edge1_index\",\"Edge2_index\"]]\n",
    "#print (edges_trans[0:3,0:1])\n",
    "#edges_trans = torch.tensor(np.ndarray(edges_trans).todense(), dtype=torch.int64)\n",
    "#print (edges_trans)\n",
    "edges = []\n",
    "for i in range(edges_trans.shape[0]):\n",
    "    edges.append([edges_trans.at[i,\"Edge1_index\"],edges_trans.at[i,\"Edge2_index\"]])\n",
    "edges = torch.tensor(edges,dtype = torch.int64).T\n",
    "print (edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571c6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof as getsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "166736cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Reaction             Type   Gene\n",
      "0  R-HSA-5336466  ProteinReaction   MRS2\n",
      "2  R-HSA-5226964  ProteinReaction   ANKH\n",
      "4  R-HSA-5339528  ProteinReaction  TUSC3\n"
     ]
    }
   ],
   "source": [
    "not_single_nodes = reaction_nodes.query('Type == \"ProteinReaction\" | Type == \"ComplexReaction\"')\n",
    "print (single_nodes.iloc[0:3,0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23745200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13590, 7979)\n",
      "(50, 7979)\n",
      "2023-09-15  10:29:36\n",
      "0\n",
      "2023-09-15  10:29:47\n",
      "1\n",
      "2023-09-15  10:29:59\n",
      "2\n",
      "2023-09-15  10:30:10\n",
      "3\n",
      "2023-09-15  10:30:21\n",
      "4\n",
      "2023-09-15  10:30:32\n",
      "5\n",
      "2023-09-15  10:30:44\n",
      "6\n",
      "2023-09-15  10:30:55\n",
      "7\n",
      "2023-09-15  10:31:07\n",
      "8\n",
      "2023-09-15  10:31:18\n",
      "9\n",
      "2023-09-15  10:31:30\n",
      "10\n",
      "2023-09-15  10:31:42\n",
      "11\n",
      "2023-09-15  10:31:53\n",
      "12\n",
      "2023-09-15  10:32:05\n",
      "13\n",
      "2023-09-15  10:32:16\n",
      "14\n",
      "2023-09-15  10:32:28\n",
      "15\n",
      "2023-09-15  10:32:39\n",
      "16\n",
      "2023-09-15  10:32:50\n",
      "17\n",
      "2023-09-15  10:33:01\n",
      "18\n",
      "2023-09-15  10:33:13\n",
      "19\n",
      "2023-09-15  10:33:24\n",
      "20\n",
      "2023-09-15  10:33:35\n",
      "21\n",
      "2023-09-15  10:33:47\n",
      "22\n",
      "2023-09-15  10:33:58\n",
      "23\n",
      "2023-09-15  10:34:09\n",
      "24\n",
      "2023-09-15  10:34:20\n",
      "25\n",
      "2023-09-15  10:34:31\n",
      "26\n",
      "2023-09-15  10:34:42\n",
      "27\n",
      "2023-09-15  10:34:53\n",
      "28\n",
      "2023-09-15  10:35:04\n",
      "29\n",
      "2023-09-15  10:35:15\n",
      "30\n",
      "2023-09-15  10:35:26\n",
      "31\n",
      "2023-09-15  10:35:37\n",
      "32\n",
      "2023-09-15  10:35:49\n",
      "33\n",
      "2023-09-15  10:36:00\n",
      "34\n",
      "2023-09-15  10:36:11\n",
      "35\n",
      "2023-09-15  10:36:21\n",
      "36\n",
      "2023-09-15  10:36:32\n",
      "37\n",
      "2023-09-15  10:36:43\n",
      "38\n",
      "2023-09-15  10:36:53\n",
      "39\n",
      "2023-09-15  10:37:04\n",
      "40\n",
      "2023-09-15  10:37:15\n",
      "41\n",
      "2023-09-15  10:37:26\n",
      "42\n",
      "2023-09-15  10:37:37\n",
      "43\n",
      "2023-09-15  10:37:48\n",
      "44\n",
      "2023-09-15  10:37:59\n",
      "45\n",
      "2023-09-15  10:38:10\n",
      "46\n",
      "2023-09-15  10:38:21\n",
      "47\n",
      "2023-09-15  10:38:32\n",
      "48\n",
      "2023-09-15  10:38:43\n",
      "49\n",
      "2023-09-15  10:38:54\n",
      "store all sample node features done\n",
      "<class 'list'>\n",
      "2023-09-15  10:38:54\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch_geometric.data import Data\n",
    "print (zero_matrix.shape)\n",
    "print (GTEx_exp_match.shape)\n",
    "gene_index_dict = dict(zip(zero_matrix.columns.to_list(),range(zero_matrix.shape[1])))\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "GTEx_exp_ndarry =  GTEx_exp_match.values\n",
    "## 每个样本的边根据入度生成小图，然后通过batch组成大图\n",
    "dataset = []\n",
    "for sample_index in range(GTEx_exp_match.shape[0]):\n",
    "    print (sample_index)\n",
    "    sample_node_feature = copy.deepcopy(zero_matrix.values)\n",
    "    for reaction_index in range(reaction_nodes.shape[0]):\n",
    "        if (reaction_nodes.at[reaction_index,\"Type\"] not in [\"ProteinReaction\",\"ComplexReaction\"]):continue # 跳过非蛋白对应的reaction\n",
    "        current_reaction_gene_index = [common_gene_list_dict[x] for x in reaction_nodes_dict[reaction_index] if x in common_gene_list]\n",
    "        sample_node_feature[[reaction_index],[current_reaction_gene_index]] = GTEx_exp_ndarry[[sample_index],[current_reaction_gene_index]]\n",
    "    sample_node_feature = Data(x=torch.tensor(sample_node_feature,dtype = torch.float32),y=sample_labels[sample_index],edge_index = edges)\n",
    "    dataset.append(sample_node_feature)\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "    #break\n",
    "print (\"store all sample node features done\")\n",
    "print (type(dataset))\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bebbb351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n"
     ]
    }
   ],
   "source": [
    "print (getsize(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50143c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (sp.csc_matrix(sample_node_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484445ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(dataset[0].num_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23730e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,num_node_features, hidden_channels,num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        #print (hidden_channels.dtype)\n",
    "        #print (num_classes.dtype)\n",
    "        self.lin = Linear(hidden_channels,num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index,batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print (x.dtype)\n",
    "        x = self.lin(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1413069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(7979, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=22, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GNN(num_node_features=7979,hidden_channels=64,num_classes=len(sample_labels_dict.keys()))\n",
    "print(model)\n",
    "#print (num_classes.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5b3a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print (dataset[0].x.dtype)\n",
    "print (dataset[0].y.dtype)\n",
    "print (dataset[0].edge_index.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del GTEx_exp\n",
    "del zero_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731ca5ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.0750\n",
      "Epoch: 002, Train Acc: 0.1250\n",
      "Epoch: 003, Train Acc: 0.1250\n",
      "Epoch: 004, Train Acc: 0.0750\n",
      "Epoch: 005, Train Acc: 0.0750\n",
      "Epoch: 006, Train Acc: 0.0750\n",
      "Epoch: 007, Train Acc: 0.0750\n",
      "Epoch: 008, Train Acc: 0.0750\n",
      "Epoch: 009, Train Acc: 0.1250\n",
      "Epoch: 010, Train Acc: 0.1250\n",
      "Epoch: 011, Train Acc: 0.0750\n",
      "Epoch: 012, Train Acc: 0.0750\n",
      "Epoch: 013, Train Acc: 0.0750\n",
      "Epoch: 014, Train Acc: 0.0750\n",
      "Epoch: 015, Train Acc: 0.1250\n",
      "Epoch: 016, Train Acc: 0.0750\n",
      "Epoch: 017, Train Acc: 0.0750\n",
      "Epoch: 018, Train Acc: 0.0750\n",
      "Epoch: 019, Train Acc: 0.0750\n",
      "Epoch: 020, Train Acc: 0.0750\n",
      "Epoch: 021, Train Acc: 0.0750\n",
      "Epoch: 022, Train Acc: 0.0750\n",
      "Epoch: 023, Train Acc: 0.1250\n",
      "Epoch: 024, Train Acc: 0.0750\n",
      "Epoch: 025, Train Acc: 0.0750\n",
      "Epoch: 026, Train Acc: 0.1250\n",
      "Epoch: 027, Train Acc: 0.0750\n",
      "Epoch: 028, Train Acc: 0.0750\n",
      "Epoch: 029, Train Acc: 0.0750\n",
      "Epoch: 030, Train Acc: 0.0750\n",
      "Epoch: 031, Train Acc: 0.1250\n",
      "Epoch: 032, Train Acc: 0.1250\n",
      "Epoch: 033, Train Acc: 0.0750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#print (data.y)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/software/miniconda3/envs/R4/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index,batch):\n\u001b[0;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[0;32m~/software/miniconda3/envs/R4/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/software/miniconda3/envs/R4/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py:86\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     83\u001b[0m     x: OptPairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_rel(out)\n\u001b[1;32m     90\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "torch.set_num_threads(48)\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_dataset = dataset[0:40]\n",
    "train_loader = DataLoader(train_dataset, batch_size=1,shuffle=True)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in dataset:\n",
    "        #print (data.y)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index,data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:                            # 批遍历测试集数据集。\n",
    "        out = model(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)                         # 使用概率最高的类别\n",
    "        correct += int((pred == data.y).sum())           # 检查真实标签\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset,\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/Torch_split/test.ptch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34f20b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[13590, 7979], edge_index=[2, 39893], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print (dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bca859aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    " \n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add') \n",
    "        # \"Add\" aggregation (Step 5).\n",
    "        #GCN类从MessagePssing中继承得到的聚合方式：“add”\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    " \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels] ——N个点，每个点in_channels维属性\n",
    "        # edge_index has shape [2, E]——E条边，每条边有出边和入边\n",
    " \n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        #添加自环\n",
    " \n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "        #对X进行线性变化\n",
    " \n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        #出边和入边\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        #各个点的入度（无向图，所以入读和出度相同）\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        #1/sqrt(di) *1/sqrt(dj)\n",
    " \n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "        #进行propagate\n",
    "        #propagate的内部会调用message(),aggregate()和update()\n",
    "        #作为消息传播的附加参数，我们传递节点嵌入x和标准化系数norm。    \n",
    " \n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        #我们需要对相邻节点特征x_j进行norm标准化\n",
    "        #这里x_j为一个张量，其中包含每条边的源节点特征，即每个节点的邻居。\n",
    " \n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "        #1/sqrt(di) *1/sqrt(dj) *X_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee633250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 39893])\n",
      "torch.Size([13590, 7979])\n",
      "torch.Size([13590, 64])\n"
     ]
    }
   ],
   "source": [
    "conv = GCNConv(7979, 64)\n",
    "x = conv(dataset[0].x,edges )\n",
    "print (edges.shape)\n",
    "print (dataset[0].x.shape)\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20053d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    #def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "     #   path = download_url(url, self.raw_dir)\n",
    "     #   ...\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print (os.getcwd())\n",
    "print(model)\n",
    "print (globals().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除clear_env.py\n",
    "def __clear_env():\n",
    "    for key in globals().keys():\n",
    "        if not key.startswith(\"__\"):# 排除系统内建函数\n",
    "            globals().pop(key)\n",
    "_clear_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self,):\n",
    "        self.datas=[1,2,(4,'a')]\n",
    "    \n",
    "    def __len__(self,):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        return self.datas[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = Mydataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "print (len(dataset))\n",
    "print (os.getcwd())\n",
    "loader = DataLoader(dataset[0:10],batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de443728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_node_feature = Data(x=torch.tensor([sample_node_feature,dtype = torch.float32),y=sample_labels[sample_index],edge_index = edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.batch import Batch\n",
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],\n",
    "])\n",
    "x_s = torch.randn(5, 8864)  # 5 nodes.\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "x_t = torch.randn(4, 8864)  # 4 nodes.\n",
    "\n",
    "edge_index_3 = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x_3 = torch.randn(4, 8864)\n",
    "\n",
    "data1= Data(x=x_s,edge_index=edge_index_s)\n",
    "data2= Data(x=x_t,edge_index=edge_index_t)\n",
    "data3= Data(x=x_3,edge_index=edge_index_3)\n",
    "data4= Data(x=x_s,edge_index=edge_index_3)\n",
    "#上面是构建3张Data图对象\n",
    "# * `Batch(Data)` in case `Data` objects are batched together\n",
    "#* `Batch(HeteroData)` in case `HeteroData` objects are batched together\n",
    "\n",
    "data_list = [data1, data2,data3,data4]\n",
    "loader = Batch.from_data_list(data_list)#调用该函数data_list里的data1、data2、data3 三张图形成一张大图，也就是batch\n",
    "loader2 = Batch.from_data_list([data1,data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "print (loader)\n",
    "print (loader2)\n",
    "print (getsizeof(loader))\n",
    "print (getsizeof(data1))\n",
    "getsize(data2)\n",
    "getsize(data3)\n",
    "getsize(data4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
