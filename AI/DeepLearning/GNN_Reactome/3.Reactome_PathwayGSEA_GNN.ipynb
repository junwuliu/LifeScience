{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1801018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch.nn import Linear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ff502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对样本进行归一化，而不是特征\n",
    "def Scale(X):\n",
    "    raw = X\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X.T)\n",
    "    X = pd.DataFrame(scaler.transform(X.T)).T\n",
    "    X.columns = raw.columns\n",
    "    X.index = raw.index\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89668d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProssGSEA(csv):\n",
    "    dataframe = pd.read_csv(csv,sep=\",\")\n",
    "    dataframe = dataframe.pivot(index = \"Name\",columns=[\"Term\"],values=[\"NES\"])\n",
    "    dataframe.columns = dataframe.columns.droplevel(0)\n",
    "    dataframe.index.rename(None, inplace=True)\n",
    "    dataframe = dataframe.dropna(axis=1, how='all') ## 去除所有都是NaN的列\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e86760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maturation of protein E_9694493\n",
      "R-HSA-9694493\n",
      "R-HSA-5657560\n"
     ]
    }
   ],
   "source": [
    "ReactomePathways_file = \"/public/ref/Msigdb/Reactome/useInfo/Human.ReactomePathways.list\"\n",
    "ReactomePathways_label = pd.read_csv(ReactomePathways_file,header=None,sep='\\t')\n",
    "#print (ReactomePathways_label.iloc[0:1,0:1])\n",
    "ReactomePathways_label.columns = [\"Name\",\"ID\"]\n",
    "ReactomePathways_label_dict = dict(zip(ReactomePathways_label[\"Name\"],ReactomePathways_label[\"ID\"])) ## Name : R-HSA*\n",
    "ReactomePathways_label_rev_dict = dict(zip(ReactomePathways_label[\"ID\"],ReactomePathways_label[\"Name\"])) # R-HSA*: Name\n",
    "print (ReactomePathways_label_rev_dict[\"R-HSA-9694493\"])\n",
    "print (ReactomePathways_label_dict[\"Maturation of protein E_9694493\"])\n",
    "print (ReactomePathways_label_dict['Hereditary fructose intolerance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63186ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17382, 2582)\n",
      "Term                      R-HSA-1059683  R-HSA-109581  R-HSA-109582  \\\n",
      "GTEX-1117F-0226-SM-5GZZ7       0.448864      0.405386      0.323341   \n",
      "GTEX-1117F-0426-SM-5EGHI       0.433999      0.412742      0.294845   \n",
      "GTEX-1117F-0526-SM-5EGHJ       0.455226      0.404896      0.320925   \n",
      "\n",
      "Term                      R-HSA-109606  R-HSA-109703  \n",
      "GTEX-1117F-0226-SM-5GZZ7      0.396594      0.360710  \n",
      "GTEX-1117F-0426-SM-5EGHI      0.408149      0.344490  \n",
      "GTEX-1117F-0526-SM-5EGHJ      0.397948      0.332731  \n",
      "[0.39794807]\n"
     ]
    }
   ],
   "source": [
    "#GSEA_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GSEA/GSEA_5tissue50.csv\"\n",
    "GSEA_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GSEA/GSEA_all.csv\"\n",
    "#GSEA_score = pd.read_csv(GSEA_file,header=0,sep=',')\n",
    "#print (GSEA_score.iloc[0:3,0:3])\n",
    "#GSEA_score[\"Term\"] = GSEA_score[\"Term\"].map(ReactomePathways_label_dict)  ## 某一列替换为对应字典值\n",
    "#GSEA_score = GSEA_score.pivot(index=\"Name\",columns=\"Term\",values=\"NES\")\n",
    "#GSEA_score.index.rename(None, inplace=True)\n",
    "#GSEA_score = GSEA_score.dropna(axis=1, how='all')\n",
    "GSEA_score =ProssGSEA(GSEA_file)\n",
    "#GSEA_score = Scale(GSEA_score)\n",
    "print (GSEA_score.shape)\n",
    "print (GSEA_score.iloc[0:3,0:5])\n",
    "#GSEA_score_ndarry =  GSEA_score.values\n",
    "GSEA_score_ndarry = preprocessing.scale(GSEA_score.values,axis=1)\n",
    "print (GSEA_score.values[[2],[3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (GSEA_score.loc[\"GTEX-1117F-0426-SM-5EGHI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e1211b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2647, 2)\n",
      "(2600, 2)\n",
      "True\n",
      "R-HSA-109582\n",
      "2\n",
      "R-HSA-1187000\n",
      "tensor([[   1,    1,    1,  ..., 2579, 2580, 2580],\n",
      "        [   3,  359, 1240,  ..., 2177,  362, 2581]])\n",
      "torch.Size([2, 2600])\n"
     ]
    }
   ],
   "source": [
    "edges_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/Human.pathway.Hierarchy.txt\"\n",
    "edges_pd = pd.read_csv(edges_file,header=None,sep='\\t')\n",
    "#edges_pd.columns = [\"Edge1\",\"Edge2\",\"Type\",\"TopLevel\"]\n",
    "edges_pd.columns = [\"Edge1\",\"Edge2\"]\n",
    "#print (edges_pd[\"Edge1\"])\n",
    "#print (type(list(edges_pd['Edge1'])))\n",
    "print (edges_pd.shape)\n",
    "edges_pd = edges_pd.loc[(edges_pd[\"Edge1\"].isin(GSEA_score.columns)) &  edges_pd[\"Edge2\"].isin(GSEA_score.columns)]\n",
    "edges_pd.reset_index()\n",
    "print (edges_pd.shape)\n",
    "edges_list = sorted(pd.concat([edges_pd['Edge1'],edges_pd['Edge2']]).unique().tolist())\n",
    "edges_dict = dict(zip(edges_list,range(len(edges_list))))\n",
    "edges_dict_rev = dict(zip(range(len(edges_list)),edges_list))\n",
    "print (\"R-HSA-109582\" in edges_list)\n",
    "print (edges_pd.at[10,\"Edge1\"])\n",
    "print (edges_dict[edges_pd.at[10,\"Edge1\"]])\n",
    "#print (edges)\n",
    "edges = list()\n",
    "print (edges_pd.at[97,\"Edge1\"])\n",
    "for i in range(edges_pd.shape[0]):\n",
    "    #print (edges_pd.at[i,\"Edge1\"])\n",
    "    #print (i)\n",
    "    edges.append([edges_dict[edges_pd.iat[i,0]],edges_dict[edges_pd.iat[i,1]]])\n",
    "    #print (edges)\n",
    "edges = torch.tensor(edges,dtype = torch.int64).T\n",
    "print (edges)\n",
    "print (edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (ReactomePathways_label_rev_dict[edges_dict_rev[2]])\n",
    "torch.save(edges,\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/pathway_edges.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3097f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (GSEA_score_ndarry[[2],[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef17af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adipose Tissue': 0, 'Adrenal Gland': 1, 'Bladder': 2, 'Blood': 3, 'Blood Vessel': 4, 'Bone Marrow': 5, 'Brain': 6, 'Breast': 7, 'Cervix Uteri': 8, 'Colon': 9, 'Esophagus': 10, 'Fallopian Tube': 11, 'Heart': 12, 'Kidney': 13, 'Liver': 14, 'Lung': 15, 'Muscle': 16, 'Nerve': 17, 'Ovary': 18, 'Pancreas': 19, 'Pituitary': 20, 'Prostate': 21, 'Salivary Gland': 22, 'Skin': 23, 'Small Intestine': 24, 'Spleen': 25, 'Stomach': 26, 'Testis': 27, 'Thyroid': 28, 'Uterus': 29, 'Vagina': 30}\n",
      "13\n",
      "tensor([13])\n"
     ]
    }
   ],
   "source": [
    "# 准备sample对应的tissue和对应的label 标签 ()\n",
    "#label_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GSEA/GSEA_5tissue50.label.txt\"\n",
    "label_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GSEA/GTEx.sample_label.txt\"\n",
    "sample_labels = pd.read_csv(label_file,header=0,sep=\"\\t\")\n",
    "sample_full_labels = sorted(list(set(sample_labels[\"SMTS\"].tolist()))) ## 唯一值\n",
    "sample_full_labels_dict = dict(zip(sample_full_labels,range(len(sample_full_labels)))) ## label对应的index\n",
    "list_labels = []\n",
    "print (sample_full_labels_dict)\n",
    "sample_dict = dict(zip(sample_labels[\"SAMPID\"],sample_labels[\"SMTS\"]))\n",
    "print (sample_full_labels_dict[sample_dict[\"GTEX-1GF9W-1326-SM-7P8PX\"]])\n",
    "for x in range(len(sample_full_labels)):\n",
    "    list_labels.append([x])\n",
    "list_labels_tensor = torch.tensor(list_labels,dtype=torch.int64)\n",
    "print (list_labels_tensor[sample_full_labels_dict[sample_dict[\"GTEX-1GF9W-1326-SM-7P8PX\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc3472",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSEA_score_ndarry[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95a463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print (GSEA_score.loc[\"GTEX-117YW-2226-SM-5N9DB\"])\n",
    "print (GSEA_score.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b289b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-24  10:39:28\n",
      "2023-09-24  10:39:29\n",
      "17382\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch_geometric.data import Data\n",
    "uniq_sample = sorted(list(set(GSEA_score.index)))\n",
    "train_dataset = list()\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "for sampleIndex,sampleName in enumerate(uniq_sample):\n",
    "    #print (sampleName)\n",
    "    sampleValue = GSEA_score_ndarry[sampleIndex]\n",
    "    sampleValue = sampleValue.reshape(sampleValue.shape[0],1)\n",
    "    #print (list_labels_tensor[sample_full_labels_dict[sample_dict[sampleName]]])\n",
    "    sample_node_feature = Data(x=torch.tensor(sampleValue,dtype = torch.float32),y=list_labels_tensor[sample_full_labels_dict[sample_dict[sampleName]]],edge_index = edges)\n",
    "    train_dataset.append(sample_node_feature)\n",
    "    #break\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "print (len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c047317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2582, 1], edge_index=[2, 2600], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print (train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = GSEA_score.loc[\"GTEX-1GF9W-1326-SM-7P8PX\"]\n",
    "#a = torch.tensor(a,dtype = torch.float32)\n",
    "print (train_dataset[0])\n",
    "print (train_dataset[0].x)\n",
    "print (train_dataset[0].y)\n",
    "#print (type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724d7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features,hidden_channels,num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels,num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. 获得节点嵌入\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)   # [batch_size, hidden_channels]\n",
    "        \n",
    "        # 3. 分类器\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "036da983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(1, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=31, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model = GNN(num_node_features=2582,hidden_channels=64,num_classes=len(sample_full_labels_dict.keys()))\n",
    "model = GNN(num_node_features=1,hidden_channels=64,num_classes=31)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55908e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2582, 1], edge_index=[2, 2600], y=[1])\n",
      "2023-09-24  10:39:38\n",
      "2023-09-24  10:40:13\n",
      "Epoch: 001, Train Acc: 0.1536\n",
      "2023-09-24  10:40:56\n",
      "Epoch: 002, Train Acc: 0.3124\n",
      "2023-09-24  10:41:40\n",
      "Epoch: 003, Train Acc: 0.4195\n",
      "2023-09-24  10:42:17\n",
      "Epoch: 004, Train Acc: 0.4651\n",
      "2023-09-24  10:43:01\n",
      "Epoch: 005, Train Acc: 0.4665\n",
      "2023-09-24  10:43:45\n",
      "Epoch: 006, Train Acc: 0.5003\n",
      "2023-09-24  10:44:27\n",
      "Epoch: 007, Train Acc: 0.5021\n",
      "2023-09-24  10:45:10\n",
      "Epoch: 008, Train Acc: 0.5197\n",
      "2023-09-24  10:45:54\n",
      "Epoch: 009, Train Acc: 0.5412\n",
      "2023-09-24  10:46:37\n",
      "Epoch: 010, Train Acc: 0.5584\n",
      "2023-09-24  10:47:20\n",
      "Epoch: 011, Train Acc: 0.5542\n",
      "2023-09-24  10:48:02\n",
      "Epoch: 012, Train Acc: 0.5913\n",
      "2023-09-24  10:48:45\n",
      "Epoch: 013, Train Acc: 0.5724\n",
      "2023-09-24  10:49:27\n",
      "Epoch: 014, Train Acc: 0.5487\n",
      "2023-09-24  10:50:09\n",
      "Epoch: 015, Train Acc: 0.6147\n",
      "2023-09-24  10:50:53\n",
      "Epoch: 016, Train Acc: 0.6081\n",
      "2023-09-24  10:51:39\n",
      "Epoch: 017, Train Acc: 0.6438\n",
      "2023-09-24  10:52:24\n",
      "Epoch: 018, Train Acc: 0.6665\n",
      "2023-09-24  10:53:09\n",
      "Epoch: 019, Train Acc: 0.6809\n",
      "2023-09-24  10:53:53\n",
      "Epoch: 020, Train Acc: 0.6802\n",
      "2023-09-24  10:54:38\n",
      "Epoch: 021, Train Acc: 0.7091\n",
      "2023-09-24  10:55:23\n",
      "Epoch: 022, Train Acc: 0.7196\n",
      "2023-09-24  10:56:08\n",
      "Epoch: 023, Train Acc: 0.7175\n",
      "2023-09-24  10:56:56\n",
      "Epoch: 024, Train Acc: 0.7241\n",
      "2023-09-24  10:57:40\n",
      "Epoch: 025, Train Acc: 0.7409\n",
      "2023-09-24  10:58:25\n",
      "Epoch: 026, Train Acc: 0.7543\n",
      "2023-09-24  10:59:11\n",
      "Epoch: 027, Train Acc: 0.7619\n",
      "2023-09-24  10:59:57\n",
      "Epoch: 028, Train Acc: 0.7665\n",
      "2023-09-24  11:00:42\n",
      "Epoch: 029, Train Acc: 0.7827\n",
      "2023-09-24  11:01:28\n",
      "Epoch: 030, Train Acc: 0.7281\n",
      "2023-09-24  11:02:12\n",
      "Epoch: 031, Train Acc: 0.7456\n",
      "2023-09-24  11:02:58\n",
      "Epoch: 032, Train Acc: 0.7567\n",
      "2023-09-24  11:03:43\n",
      "Epoch: 033, Train Acc: 0.7848\n",
      "2023-09-24  11:04:28\n",
      "Epoch: 034, Train Acc: 0.7999\n",
      "2023-09-24  11:05:13\n",
      "Epoch: 035, Train Acc: 0.8012\n",
      "2023-09-24  11:05:56\n",
      "Epoch: 036, Train Acc: 0.7936\n",
      "2023-09-24  11:06:38\n",
      "Epoch: 037, Train Acc: 0.8067\n",
      "2023-09-24  11:07:23\n",
      "Epoch: 038, Train Acc: 0.8116\n",
      "2023-09-24  11:08:07\n",
      "Epoch: 039, Train Acc: 0.7259\n",
      "2023-09-24  11:08:51\n",
      "Epoch: 040, Train Acc: 0.7951\n",
      "2023-09-24  11:09:34\n",
      "Epoch: 041, Train Acc: 0.8125\n",
      "2023-09-24  11:10:18\n",
      "Epoch: 042, Train Acc: 0.8156\n",
      "2023-09-24  11:11:02\n",
      "Epoch: 043, Train Acc: 0.8116\n",
      "2023-09-24  11:11:41\n",
      "Epoch: 044, Train Acc: 0.8082\n",
      "2023-09-24  11:12:24\n",
      "Epoch: 045, Train Acc: 0.8310\n",
      "2023-09-24  11:13:08\n",
      "Epoch: 046, Train Acc: 0.8181\n",
      "2023-09-24  11:13:52\n",
      "Epoch: 047, Train Acc: 0.8371\n",
      "2023-09-24  11:14:36\n",
      "Epoch: 048, Train Acc: 0.8322\n",
      "2023-09-24  11:15:20\n",
      "Epoch: 049, Train Acc: 0.8259\n",
      "2023-09-24  11:16:03\n",
      "Epoch: 050, Train Acc: 0.8331\n",
      "2023-09-24  11:16:47\n",
      "Epoch: 051, Train Acc: 0.8494\n",
      "2023-09-24  11:17:31\n",
      "Epoch: 052, Train Acc: 0.8309\n",
      "2023-09-24  11:18:14\n",
      "Epoch: 053, Train Acc: 0.8308\n",
      "2023-09-24  11:18:58\n",
      "Epoch: 054, Train Acc: 0.8194\n",
      "2023-09-24  11:19:41\n",
      "Epoch: 055, Train Acc: 0.8242\n",
      "2023-09-24  11:20:24\n",
      "Epoch: 056, Train Acc: 0.8498\n",
      "2023-09-24  11:21:06\n",
      "Epoch: 057, Train Acc: 0.8462\n",
      "2023-09-24  11:21:49\n",
      "Epoch: 058, Train Acc: 0.8551\n",
      "2023-09-24  11:22:28\n",
      "Epoch: 059, Train Acc: 0.8492\n",
      "2023-09-24  11:23:10\n",
      "Epoch: 060, Train Acc: 0.8345\n",
      "2023-09-24  11:23:53\n",
      "Epoch: 061, Train Acc: 0.8395\n",
      "2023-09-24  11:24:36\n",
      "Epoch: 062, Train Acc: 0.8656\n",
      "2023-09-24  11:25:19\n",
      "Epoch: 063, Train Acc: 0.8693\n",
      "2023-09-24  11:26:03\n",
      "Epoch: 064, Train Acc: 0.8652\n",
      "2023-09-24  11:26:46\n",
      "Epoch: 065, Train Acc: 0.8716\n",
      "2023-09-24  11:27:28\n",
      "Epoch: 066, Train Acc: 0.8664\n",
      "2023-09-24  11:28:12\n",
      "Epoch: 067, Train Acc: 0.8552\n",
      "2023-09-24  11:28:54\n",
      "Epoch: 068, Train Acc: 0.8727\n",
      "2023-09-24  11:29:37\n",
      "Epoch: 069, Train Acc: 0.8675\n",
      "2023-09-24  11:30:19\n",
      "Epoch: 070, Train Acc: 0.8732\n",
      "2023-09-24  11:31:02\n",
      "Epoch: 071, Train Acc: 0.8865\n",
      "2023-09-24  11:31:44\n",
      "Epoch: 072, Train Acc: 0.8694\n",
      "2023-09-24  11:32:27\n",
      "Epoch: 073, Train Acc: 0.8234\n",
      "2023-09-24  11:33:10\n",
      "Epoch: 074, Train Acc: 0.8794\n",
      "2023-09-24  11:33:53\n",
      "Epoch: 075, Train Acc: 0.8676\n",
      "2023-09-24  11:34:35\n",
      "Epoch: 076, Train Acc: 0.8781\n",
      "2023-09-24  11:35:19\n",
      "Epoch: 077, Train Acc: 0.8719\n",
      "2023-09-24  11:36:02\n",
      "Epoch: 078, Train Acc: 0.8631\n",
      "2023-09-24  11:36:45\n",
      "Epoch: 079, Train Acc: 0.8800\n",
      "2023-09-24  11:37:28\n",
      "Epoch: 080, Train Acc: 0.8954\n",
      "2023-09-24  11:38:11\n",
      "Epoch: 081, Train Acc: 0.8901\n",
      "2023-09-24  11:38:56\n",
      "Epoch: 082, Train Acc: 0.8649\n",
      "2023-09-24  11:39:39\n",
      "Epoch: 083, Train Acc: 0.8875\n",
      "2023-09-24  11:40:22\n",
      "Epoch: 084, Train Acc: 0.8987\n",
      "2023-09-24  11:41:05\n",
      "Epoch: 085, Train Acc: 0.9011\n",
      "2023-09-24  11:41:48\n",
      "Epoch: 086, Train Acc: 0.8844\n",
      "2023-09-24  11:42:29\n",
      "Epoch: 087, Train Acc: 0.8879\n",
      "2023-09-24  11:43:12\n",
      "Epoch: 088, Train Acc: 0.8836\n",
      "2023-09-24  11:43:55\n",
      "Epoch: 089, Train Acc: 0.8945\n",
      "2023-09-24  11:44:38\n",
      "Epoch: 090, Train Acc: 0.8909\n",
      "2023-09-24  11:45:21\n",
      "Epoch: 091, Train Acc: 0.8972\n",
      "2023-09-24  11:46:04\n",
      "Epoch: 092, Train Acc: 0.8952\n",
      "2023-09-24  11:46:47\n",
      "Epoch: 093, Train Acc: 0.8901\n",
      "2023-09-24  11:47:29\n",
      "Epoch: 094, Train Acc: 0.8864\n",
      "2023-09-24  11:48:12\n",
      "Epoch: 095, Train Acc: 0.9095\n",
      "2023-09-24  11:48:48\n",
      "Epoch: 096, Train Acc: 0.9042\n",
      "2023-09-24  11:49:30\n",
      "Epoch: 097, Train Acc: 0.8651\n",
      "2023-09-24  11:50:13\n",
      "Epoch: 098, Train Acc: 0.9021\n",
      "2023-09-24  11:50:56\n",
      "Epoch: 099, Train Acc: 0.8944\n",
      "2023-09-24  11:51:39\n",
      "Epoch: 100, Train Acc: 0.9100\n",
      "2023-09-24  11:52:22\n",
      "Epoch: 101, Train Acc: 0.9042\n",
      "2023-09-24  11:53:06\n",
      "Epoch: 102, Train Acc: 0.9041\n",
      "2023-09-24  11:53:48\n",
      "Epoch: 103, Train Acc: 0.9033\n",
      "2023-09-24  11:54:31\n",
      "Epoch: 104, Train Acc: 0.9029\n",
      "2023-09-24  11:55:14\n",
      "Epoch: 105, Train Acc: 0.8940\n",
      "2023-09-24  11:55:57\n",
      "Epoch: 106, Train Acc: 0.9064\n",
      "2023-09-24  11:56:40\n",
      "Epoch: 107, Train Acc: 0.9004\n",
      "2023-09-24  11:57:22\n",
      "Epoch: 108, Train Acc: 0.9103\n",
      "2023-09-24  11:58:05\n",
      "Epoch: 109, Train Acc: 0.9168\n",
      "2023-09-24  11:58:49\n",
      "Epoch: 110, Train Acc: 0.9102\n",
      "2023-09-24  11:59:32\n",
      "Epoch: 111, Train Acc: 0.9082\n",
      "2023-09-24  12:00:16\n",
      "Epoch: 112, Train Acc: 0.9180\n",
      "2023-09-24  12:01:00\n",
      "Epoch: 113, Train Acc: 0.9091\n",
      "2023-09-24  12:01:44\n",
      "Epoch: 114, Train Acc: 0.9044\n",
      "2023-09-24  12:02:26\n",
      "Epoch: 115, Train Acc: 0.9161\n",
      "2023-09-24  12:03:10\n",
      "Epoch: 116, Train Acc: 0.9091\n",
      "2023-09-24  12:03:54\n",
      "Epoch: 117, Train Acc: 0.9138\n",
      "2023-09-24  12:04:38\n",
      "Epoch: 118, Train Acc: 0.9206\n",
      "2023-09-24  12:05:22\n",
      "Epoch: 119, Train Acc: 0.9131\n",
      "2023-09-24  12:06:05\n",
      "Epoch: 120, Train Acc: 0.9096\n",
      "2023-09-24  12:06:49\n",
      "Epoch: 121, Train Acc: 0.9049\n",
      "2023-09-24  12:07:32\n",
      "Epoch: 122, Train Acc: 0.9153\n",
      "2023-09-24  12:08:16\n",
      "Epoch: 123, Train Acc: 0.9158\n",
      "2023-09-24  12:08:59\n",
      "Epoch: 124, Train Acc: 0.9181\n",
      "2023-09-24  12:09:43\n",
      "Epoch: 125, Train Acc: 0.9134\n",
      "2023-09-24  12:10:26\n",
      "Epoch: 126, Train Acc: 0.9155\n",
      "2023-09-24  12:11:09\n",
      "Epoch: 127, Train Acc: 0.9263\n",
      "2023-09-24  12:11:52\n",
      "Epoch: 128, Train Acc: 0.9188\n",
      "2023-09-24  12:12:36\n",
      "Epoch: 129, Train Acc: 0.9054\n",
      "2023-09-24  12:13:19\n",
      "Epoch: 130, Train Acc: 0.9203\n",
      "2023-09-24  12:14:03\n",
      "Epoch: 131, Train Acc: 0.9191\n",
      "2023-09-24  12:14:46\n",
      "Epoch: 132, Train Acc: 0.9269\n",
      "2023-09-24  12:15:31\n",
      "Epoch: 133, Train Acc: 0.9206\n",
      "2023-09-24  12:16:15\n",
      "Epoch: 134, Train Acc: 0.9198\n",
      "2023-09-24  12:16:59\n",
      "Epoch: 135, Train Acc: 0.9179\n",
      "2023-09-24  12:17:43\n",
      "Epoch: 136, Train Acc: 0.9122\n",
      "2023-09-24  12:18:26\n",
      "Epoch: 137, Train Acc: 0.9279\n",
      "2023-09-24  12:19:09\n",
      "Epoch: 138, Train Acc: 0.9074\n",
      "2023-09-24  12:19:52\n",
      "Epoch: 139, Train Acc: 0.9225\n",
      "2023-09-24  12:20:36\n",
      "Epoch: 140, Train Acc: 0.9269\n",
      "2023-09-24  12:21:19\n",
      "Epoch: 141, Train Acc: 0.9303\n",
      "2023-09-24  12:22:02\n",
      "Epoch: 142, Train Acc: 0.9109\n",
      "2023-09-24  12:22:46\n",
      "Epoch: 143, Train Acc: 0.9288\n",
      "2023-09-24  12:23:29\n",
      "Epoch: 144, Train Acc: 0.9159\n",
      "2023-09-24  12:24:12\n",
      "Epoch: 145, Train Acc: 0.9311\n",
      "2023-09-24  12:24:55\n",
      "Epoch: 146, Train Acc: 0.9140\n",
      "2023-09-24  12:25:38\n",
      "Epoch: 147, Train Acc: 0.9125\n",
      "2023-09-24  12:26:21\n",
      "Epoch: 148, Train Acc: 0.9278\n",
      "2023-09-24  12:27:04\n",
      "Epoch: 149, Train Acc: 0.9319\n",
      "2023-09-24  12:27:47\n",
      "Epoch: 150, Train Acc: 0.9268\n",
      "2023-09-24  12:28:30\n",
      "Epoch: 151, Train Acc: 0.9362\n",
      "2023-09-24  12:29:14\n",
      "Epoch: 152, Train Acc: 0.9339\n",
      "2023-09-24  12:29:57\n",
      "Epoch: 153, Train Acc: 0.9278\n",
      "2023-09-24  12:30:41\n",
      "Epoch: 154, Train Acc: 0.9368\n",
      "2023-09-24  12:31:25\n",
      "Epoch: 155, Train Acc: 0.9291\n",
      "2023-09-24  12:32:09\n",
      "Epoch: 156, Train Acc: 0.9377\n",
      "2023-09-24  12:32:53\n",
      "Epoch: 157, Train Acc: 0.9192\n",
      "2023-09-24  12:33:37\n",
      "Epoch: 158, Train Acc: 0.9079\n",
      "2023-09-24  12:34:20\n",
      "Epoch: 159, Train Acc: 0.9215\n",
      "2023-09-24  12:35:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Train Acc: 0.9368\n",
      "2023-09-24  12:35:47\n",
      "Epoch: 161, Train Acc: 0.9339\n",
      "2023-09-24  12:36:31\n",
      "Epoch: 162, Train Acc: 0.9362\n",
      "2023-09-24  12:37:15\n",
      "Epoch: 163, Train Acc: 0.9312\n",
      "2023-09-24  12:37:58\n",
      "Epoch: 164, Train Acc: 0.9256\n",
      "2023-09-24  12:38:42\n",
      "Epoch: 165, Train Acc: 0.9226\n",
      "2023-09-24  12:39:25\n",
      "Epoch: 166, Train Acc: 0.9398\n",
      "2023-09-24  12:40:09\n",
      "Epoch: 167, Train Acc: 0.9368\n",
      "2023-09-24  12:40:54\n",
      "Epoch: 168, Train Acc: 0.9229\n",
      "2023-09-24  12:41:37\n",
      "Epoch: 169, Train Acc: 0.9277\n",
      "2023-09-24  12:42:21\n",
      "Epoch: 170, Train Acc: 0.9356\n",
      "2023-09-24  12:43:04\n",
      "Epoch: 171, Train Acc: 0.9208\n",
      "2023-09-24  12:43:48\n",
      "Epoch: 172, Train Acc: 0.9340\n",
      "2023-09-24  12:44:32\n",
      "Epoch: 173, Train Acc: 0.9377\n",
      "2023-09-24  12:45:15\n",
      "Epoch: 174, Train Acc: 0.9361\n",
      "2023-09-24  12:45:59\n",
      "Epoch: 175, Train Acc: 0.9396\n",
      "2023-09-24  12:46:43\n",
      "Epoch: 176, Train Acc: 0.9392\n",
      "2023-09-24  12:47:26\n",
      "Epoch: 177, Train Acc: 0.9330\n",
      "2023-09-24  12:48:10\n",
      "Epoch: 178, Train Acc: 0.9203\n",
      "2023-09-24  12:48:55\n",
      "Epoch: 179, Train Acc: 0.9388\n",
      "2023-09-24  12:49:38\n",
      "Epoch: 180, Train Acc: 0.9355\n",
      "2023-09-24  12:50:23\n",
      "Epoch: 181, Train Acc: 0.9349\n",
      "2023-09-24  12:51:08\n",
      "Epoch: 182, Train Acc: 0.9324\n",
      "2023-09-24  12:51:52\n",
      "Epoch: 183, Train Acc: 0.9350\n",
      "2023-09-24  12:52:35\n",
      "Epoch: 184, Train Acc: 0.9341\n",
      "2023-09-24  12:53:19\n",
      "Epoch: 185, Train Acc: 0.9455\n",
      "2023-09-24  12:55:31\n",
      "Epoch: 188, Train Acc: 0.9296\n",
      "2023-09-24  12:56:15\n",
      "Epoch: 189, Train Acc: 0.9397\n",
      "2023-09-24  12:57:00\n",
      "Epoch: 190, Train Acc: 0.9452\n",
      "2023-09-24  12:57:43\n",
      "Epoch: 191, Train Acc: 0.9448\n",
      "2023-09-24  12:58:27\n",
      "Epoch: 192, Train Acc: 0.9238\n",
      "2023-09-24  12:59:11\n",
      "Epoch: 193, Train Acc: 0.9172\n",
      "2023-09-24  12:59:55\n",
      "Epoch: 194, Train Acc: 0.9339\n",
      "2023-09-24  13:00:38\n",
      "Epoch: 195, Train Acc: 0.9249\n",
      "2023-09-24  13:01:21\n",
      "Epoch: 196, Train Acc: 0.9463\n",
      "2023-09-24  13:02:04\n",
      "Epoch: 197, Train Acc: 0.9424\n",
      "2023-09-24  13:02:50\n",
      "Epoch: 198, Train Acc: 0.9372\n",
      "2023-09-24  13:03:34\n",
      "Epoch: 199, Train Acc: 0.9386\n",
      "2023-09-24  13:04:18\n",
      "Epoch: 200, Train Acc: 0.9352\n",
      "2023-09-24  13:05:01\n",
      "Epoch: 201, Train Acc: 0.9449\n",
      "2023-09-24  13:05:44\n",
      "Epoch: 202, Train Acc: 0.9286\n",
      "2023-09-24  13:06:27\n",
      "Epoch: 203, Train Acc: 0.9455\n",
      "2023-09-24  13:07:11\n",
      "Epoch: 204, Train Acc: 0.9468\n",
      "2023-09-24  13:07:53\n",
      "Epoch: 205, Train Acc: 0.9274\n",
      "2023-09-24  13:08:36\n",
      "Epoch: 206, Train Acc: 0.9447\n",
      "2023-09-24  13:09:20\n",
      "Epoch: 207, Train Acc: 0.9383\n",
      "2023-09-24  13:10:02\n",
      "Epoch: 208, Train Acc: 0.9397\n",
      "2023-09-24  13:10:46\n",
      "Epoch: 209, Train Acc: 0.9418\n",
      "2023-09-24  13:11:30\n",
      "Epoch: 210, Train Acc: 0.9426\n",
      "2023-09-24  13:12:14\n",
      "Epoch: 211, Train Acc: 0.9404\n",
      "2023-09-24  13:12:58\n",
      "Epoch: 212, Train Acc: 0.9486\n",
      "2023-09-24  13:13:42\n",
      "Epoch: 213, Train Acc: 0.9498\n",
      "2023-09-24  13:14:27\n",
      "Epoch: 214, Train Acc: 0.9421\n",
      "2023-09-24  13:15:10\n",
      "Epoch: 215, Train Acc: 0.9457\n",
      "2023-09-24  13:15:54\n",
      "Epoch: 216, Train Acc: 0.9498\n",
      "2023-09-24  13:16:38\n",
      "Epoch: 217, Train Acc: 0.9449\n",
      "2023-09-24  13:17:22\n",
      "Epoch: 218, Train Acc: 0.9517\n",
      "2023-09-24  13:18:06\n",
      "Epoch: 219, Train Acc: 0.9442\n",
      "2023-09-24  13:18:50\n",
      "Epoch: 220, Train Acc: 0.9419\n",
      "2023-09-24  13:19:33\n",
      "Epoch: 221, Train Acc: 0.9446\n",
      "2023-09-24  13:20:16\n",
      "Epoch: 222, Train Acc: 0.9385\n",
      "2023-09-24  13:21:01\n",
      "Epoch: 223, Train Acc: 0.9452\n",
      "2023-09-24  13:21:43\n",
      "Epoch: 224, Train Acc: 0.9392\n",
      "2023-09-24  13:22:26\n",
      "Epoch: 225, Train Acc: 0.9470\n",
      "2023-09-24  13:23:08\n",
      "Epoch: 226, Train Acc: 0.9422\n",
      "2023-09-24  13:23:52\n",
      "Epoch: 227, Train Acc: 0.9482\n",
      "2023-09-24  13:24:35\n",
      "Epoch: 228, Train Acc: 0.9466\n",
      "2023-09-24  13:25:19\n",
      "Epoch: 229, Train Acc: 0.9378\n",
      "2023-09-24  13:26:03\n",
      "Epoch: 230, Train Acc: 0.9526\n",
      "2023-09-24  13:26:46\n",
      "Epoch: 231, Train Acc: 0.9476\n",
      "2023-09-24  13:27:30\n",
      "Epoch: 232, Train Acc: 0.9334\n",
      "2023-09-24  13:28:14\n",
      "Epoch: 233, Train Acc: 0.9477\n",
      "2023-09-24  13:28:58\n",
      "Epoch: 234, Train Acc: 0.9444\n",
      "2023-09-24  13:29:42\n",
      "Epoch: 235, Train Acc: 0.9524\n",
      "2023-09-24  13:30:26\n",
      "Epoch: 236, Train Acc: 0.9531\n",
      "2023-09-24  13:31:09\n",
      "Epoch: 237, Train Acc: 0.9456\n",
      "2023-09-24  13:31:54\n",
      "Epoch: 238, Train Acc: 0.9421\n",
      "2023-09-24  13:32:38\n",
      "Epoch: 239, Train Acc: 0.9466\n",
      "2023-09-24  13:33:21\n",
      "Epoch: 240, Train Acc: 0.9481\n",
      "2023-09-24  13:34:04\n",
      "Epoch: 241, Train Acc: 0.9372\n",
      "2023-09-24  13:34:49\n",
      "Epoch: 242, Train Acc: 0.9526\n",
      "2023-09-24  13:35:33\n",
      "Epoch: 243, Train Acc: 0.9472\n",
      "2023-09-24  13:36:17\n",
      "Epoch: 244, Train Acc: 0.9475\n",
      "2023-09-24  13:37:00\n",
      "Epoch: 245, Train Acc: 0.9477\n",
      "2023-09-24  13:37:44\n",
      "Epoch: 246, Train Acc: 0.9521\n",
      "2023-09-24  13:38:27\n",
      "Epoch: 247, Train Acc: 0.9525\n",
      "2023-09-24  13:39:11\n",
      "Epoch: 248, Train Acc: 0.9534\n",
      "2023-09-24  13:39:55\n",
      "Epoch: 249, Train Acc: 0.9499\n",
      "2023-09-24  13:40:39\n",
      "Epoch: 250, Train Acc: 0.9427\n",
      "2023-09-24  13:41:23\n",
      "Epoch: 251, Train Acc: 0.9431\n",
      "2023-09-24  13:42:06\n",
      "Epoch: 252, Train Acc: 0.9498\n",
      "2023-09-24  13:42:50\n",
      "Epoch: 253, Train Acc: 0.9490\n",
      "2023-09-24  13:43:29\n",
      "Epoch: 254, Train Acc: 0.9465\n",
      "2023-09-24  13:44:12\n",
      "Epoch: 255, Train Acc: 0.9499\n",
      "2023-09-24  13:44:55\n",
      "Epoch: 256, Train Acc: 0.9392\n",
      "2023-09-24  13:45:39\n",
      "Epoch: 257, Train Acc: 0.9527\n",
      "2023-09-24  13:46:24\n",
      "Epoch: 258, Train Acc: 0.9456\n",
      "2023-09-24  13:47:07\n",
      "Epoch: 259, Train Acc: 0.9536\n",
      "2023-09-24  13:47:51\n",
      "Epoch: 260, Train Acc: 0.9479\n",
      "2023-09-24  13:48:33\n",
      "Epoch: 261, Train Acc: 0.9451\n",
      "2023-09-24  13:49:16\n",
      "Epoch: 262, Train Acc: 0.9494\n",
      "2023-09-24  13:50:00\n",
      "Epoch: 263, Train Acc: 0.9526\n",
      "2023-09-24  13:50:43\n",
      "Epoch: 264, Train Acc: 0.9341\n",
      "2023-09-24  13:51:25\n",
      "Epoch: 265, Train Acc: 0.9518\n",
      "2023-09-24  13:52:09\n",
      "Epoch: 266, Train Acc: 0.9532\n",
      "2023-09-24  13:52:52\n",
      "Epoch: 267, Train Acc: 0.9465\n",
      "2023-09-24  13:53:35\n",
      "Epoch: 268, Train Acc: 0.9515\n",
      "2023-09-24  13:54:19\n",
      "Epoch: 269, Train Acc: 0.9539\n",
      "2023-09-24  13:55:02\n",
      "Epoch: 270, Train Acc: 0.9520\n",
      "2023-09-24  13:55:45\n",
      "Epoch: 271, Train Acc: 0.9473\n",
      "2023-09-24  13:56:27\n",
      "Epoch: 272, Train Acc: 0.9544\n",
      "2023-09-24  13:57:10\n",
      "Epoch: 273, Train Acc: 0.9552\n",
      "2023-09-24  13:57:53\n",
      "Epoch: 274, Train Acc: 0.9507\n",
      "2023-09-24  13:58:37\n",
      "Epoch: 275, Train Acc: 0.9566\n",
      "2023-09-24  13:59:20\n",
      "Epoch: 276, Train Acc: 0.9569\n",
      "2023-09-24  14:00:02\n",
      "Epoch: 277, Train Acc: 0.9555\n",
      "2023-09-24  14:00:46\n",
      "Epoch: 278, Train Acc: 0.9519\n",
      "2023-09-24  14:01:29\n",
      "Epoch: 279, Train Acc: 0.9579\n",
      "2023-09-24  14:02:13\n",
      "Epoch: 280, Train Acc: 0.9440\n",
      "2023-09-24  14:02:56\n",
      "Epoch: 281, Train Acc: 0.9572\n",
      "2023-09-24  14:03:39\n",
      "Epoch: 282, Train Acc: 0.9539\n",
      "2023-09-24  14:04:24\n",
      "Epoch: 283, Train Acc: 0.9569\n",
      "2023-09-24  14:05:08\n",
      "Epoch: 284, Train Acc: 0.9533\n",
      "2023-09-24  14:05:51\n",
      "Epoch: 285, Train Acc: 0.9577\n",
      "2023-09-24  14:06:31\n",
      "Epoch: 286, Train Acc: 0.9534\n",
      "2023-09-24  14:07:15\n",
      "Epoch: 287, Train Acc: 0.9568\n",
      "2023-09-24  14:07:59\n",
      "Epoch: 288, Train Acc: 0.9514\n",
      "2023-09-24  14:08:43\n",
      "Epoch: 289, Train Acc: 0.9412\n",
      "2023-09-24  14:09:27\n",
      "Epoch: 290, Train Acc: 0.9605\n",
      "2023-09-24  14:10:12\n",
      "Epoch: 291, Train Acc: 0.9472\n",
      "2023-09-24  14:10:56\n",
      "Epoch: 292, Train Acc: 0.9569\n",
      "2023-09-24  14:11:39\n",
      "Epoch: 293, Train Acc: 0.9524\n",
      "2023-09-24  14:12:23\n",
      "Epoch: 294, Train Acc: 0.9579\n",
      "2023-09-24  14:13:06\n",
      "Epoch: 295, Train Acc: 0.9589\n",
      "2023-09-24  14:13:51\n",
      "Epoch: 296, Train Acc: 0.9552\n",
      "2023-09-24  14:14:34\n",
      "Epoch: 297, Train Acc: 0.9541\n",
      "2023-09-24  14:15:17\n",
      "Epoch: 298, Train Acc: 0.9522\n",
      "2023-09-24  14:16:01\n",
      "Epoch: 299, Train Acc: 0.9536\n",
      "2023-09-24  14:16:44\n",
      "Epoch: 300, Train Acc: 0.9492\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "torch.set_num_threads(48)\n",
    "print (train_dataset[0])\n",
    "train_dataset1 = train_dataset[0:17000]\n",
    "train_loader = DataLoader(train_dataset1, batch_size=30,shuffle=True)\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        #print (data.y)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index,data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:                            # 批遍历测试集数据集。\n",
    "        out = model(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        #print (pred,data.y)\n",
    "        correct += int((pred == data.y).sum())           # 检查真实标签\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "model.train()\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "\n",
    "for epoch in range(1, 301):\n",
    "    train()\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "    train_acc = test(train_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9f2026",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mtrain_loader\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "print (train_loader[0].batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a914fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:                            # 批遍历测试集数据集。\n",
    "        out = model(data.x, data.edge_index, data.batch) # 一次前向传播\n",
    "        pred = out.argmax(dim=1)   # 使用概率最高的类别\n",
    "        print (pred,data.y)\n",
    "        correct += int((pred == data.y).sum())           # 检查真实标签\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c74fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382\n",
      "Test Acc: 0.9255\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "model.eval()\n",
    "test_data = train_dataset[16000:]\n",
    "print (len(test_data))\n",
    "test_loader = DataLoader(test_data, batch_size=10,shuffle=True)\n",
    "test_acc = test(test_loader)\n",
    "#print (test_acc.)\n",
    "print(f'Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f719db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#print (test_loader)\n",
    "data = test_data[1]\n",
    "#print (data)\n",
    "out = model(data.x, data.edge_index,data.batch) # 一次前向传播\n",
    "print (out)\n",
    "pred = out.argmax(dim=1)\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85e4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "saved_dict = {\n",
    " 'model': model.state_dict(),\n",
    " 'opt': optimizer.state_dict()\n",
    "}\n",
    "torch.save(saved_dict, '/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GTEx.nomalizeSample.axis1.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TCGA_GSEA_score = TotalSample_GSEA.csv \n",
    "TCGA_GSEA_score = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/TCGA_exp/GSEA/TotalSample_GSEA.csv\",header=0,sep=',')\n",
    "TCGA_GSEA_score = TCGA_GSEA_score.pivot(index=\"Name\",columns=\"Term\",values=\"NES\")\n",
    "TCGA_GSEA_score.index.rename(None, inplace=True)\n",
    "TCGA_GSEA_score = TCGA_GSEA_score.dropna(axis=1, how='all')\n",
    "print (TCGA_GSEA_score.shape)\n",
    "print (TCGA_GSEA_score.iloc[0:3,0:5])\n",
    "TCGA_GSEA_score_ndarry = preprocessing.scale(TCGA_GSEA_score.values,axis=1)\n",
    "print (TCGA_GSEA_score_ndarry[[2],[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 随机切割 数据\n",
    "from torch.utils.data import random_split\n",
    "TCGA_train_dataset, TCGA_test_dataset = random_split(\n",
    "    dataset=tuning_dataset,\n",
    "    lengths=[365, 365],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")\n",
    "print (len(TCGA_train_dataset))\n",
    "print (len(TCGA_test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
