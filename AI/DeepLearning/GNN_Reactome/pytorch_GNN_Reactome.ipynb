{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d65a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import GCNConv,GATConv,SAGEConv\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86475fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把标签转换成onehot\n",
    "def encode_onehot(labels):                                   \n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21900968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 测试onehot函数\n",
    "labels = (\"input\",\"output\",\"entityFunctionalStatus\",\"catalystActivity\",\"regulatedBy\")\n",
    "a = encode_onehot(labels)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc18b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):                                          # 归一化\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten() ## 幂\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv) # 对角化\n",
    "    mx = r_mat_inv.dot(mx) # 乘积\n",
    "    mx = mx * 10000\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19467a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.  4.  6.  8.]\n",
      " [10. 12. 14. 16. 18.]\n",
      " [20. 22. 24. 26. 28.]]\n",
      "[ 20.  70. 120.]\n",
      "[0.05       0.01428571 0.00833333]\n",
      "[[0.         0.1        0.2        0.3        0.4       ]\n",
      " [0.14285715 0.17142858 0.2        0.22857143 0.25714287]\n",
      " [0.16666667 0.18333334 0.20000002 0.21666668 0.23333335]]\n"
     ]
    }
   ],
   "source": [
    "# 测试normailize 函数\n",
    "mx1 =  np.arange(0, 30, 2).reshape(3,5).astype(np.float32)\n",
    "print (mx1)\n",
    "rowsum = np.array(mx1.sum(1))\n",
    "print (rowsum)\n",
    "r_inv = np.power(rowsum, -1).flatten()\n",
    "print (r_inv)\n",
    "print (normalize(mx1))\n",
    "#a = torch.rand(2,3,4)\n",
    "#print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34bebbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Sample          Tissue  DDX11L1\n",
      "0  GTEX-1117F-0226-SM-5GZZ7  Adipose Tissue      0.0\n",
      "1  GTEX-1117F-0426-SM-5EGHI          Muscle      0.0\n",
      "2  GTEX-1117F-0526-SM-5EGHJ    Blood Vessel      0.0\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "GTEx_exp = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/GTEx_exp/GTEx_exp.csv.test\",sep=',',header=0)\n",
    "print (GTEx_exp.iloc[0:3,0:3])\n",
    "sample_labels = GTEx_exp[\"Tissue\"]\n",
    "sample_labels_onehot = encode_onehot(sample_labels)\n",
    "print (sample_labels_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cfd4b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DDX11L1    WASH7P     MT-TE\n",
      "0      0.0  0.443207  0.553907\n",
      "1      0.0  0.443591  1.069985\n",
      "2      0.0  0.442149  0.668421\n"
     ]
    }
   ],
   "source": [
    "#print (GTEx_exp.iloc[0:3,-2:-1])\n",
    "# log2表达量归一化\n",
    "normlizeGTEx = pd.DataFrame(normalize(GTEx_exp.iloc[:,2:GTEx_exp.shape[1]]),columns=GTEx_exp.iloc[:,2:GTEx_exp.shape[1]].columns)\n",
    "#print (pd.DataFrame(normlizeGTEx).shape)\n",
    "print (normlizeGTEx.iloc[0:3,[0,1,-4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e0845009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 54393)\n"
     ]
    }
   ],
   "source": [
    "print (normlizeGTEx.shape)\n",
    "del GTEx_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f1b1cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13590, 2)\n",
      "(13590, 9029)\n"
     ]
    }
   ],
   "source": [
    "# 整理蛋白和基因名的对应关系\n",
    "reaction_protein = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reaction_related.protein\",sep='\\t',header=None)\n",
    "reaction_protein_list = reaction_protein.loc[:,0].tolist()\n",
    "#reaction_protein.columns = [\"Protein\"] ## 9233 proteins, 其表达量作为节点reaction的特征\n",
    "P2Symbol = pd.read_csv(\"/public/ref/UniProt/HUMAN_9606_id.GeneName\",sep='\\t',header=None)\n",
    "P2Symbol.columns = [\"Protein\",\"Genecard\",\"GeneSymbol\"]\n",
    "P2Symbol_dict = P2Symbol.set_index(['Protein'])['GeneSymbol'].to_dict()\n",
    "reaction_gene_list = []\n",
    "for p in reaction_protein_list:\n",
    "    if (p in P2Symbol_dict.keys()):\n",
    "        reaction_gene_list.append(P2Symbol_dict[p])\n",
    "    else:\n",
    "        pass\n",
    "        #reaction_gene_list.append(p)\n",
    "reaction_nodes = pd.read_csv(\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.nodes.txt\",sep='\\t',header=None)\n",
    "print (reaction_nodes.shape)\n",
    "reaction_nodes.columns = [\"Reaction\",\"Type\"]\n",
    "zero_matrix = pd.DataFrame(np.zeros((reaction_nodes.shape[0],len(reaction_gene_list))),columns = reaction_gene_list)\n",
    "print (zero_matrix.shape)\n",
    "#print (reaction_nodes.iloc[0:3,0:3])\n",
    "#print (zero_matrix.iloc[0:3,0:3])\n",
    "#nodes_init_matrix = pd.concat([reaction_nodes,zero_matrix],axis=1) ## 初始化节点特征 （可以不用带）\n",
    "#print (nodes_init_matrix.iloc[0:10,0:3])\n",
    "#reaction_edges = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.edges.txt\"\n",
    "## 根据表达量生成 样本的nodes_feature \n",
    "#print (nodes_init_matrix.loc[0,\"Reaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3c5a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13589, 9235)\n",
      "        Reaction             Type\n",
      "0  R-HSA-5336466  ProteinReaction\n",
      "1  R-HSA-5216072     EwasReaction\n",
      "2  R-HSA-5226964  ProteinReaction\n",
      "3  R-HSA-5215980     EwasReaction\n",
      "4  R-HSA-5339528  ProteinReaction\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (nodes_init_matrix.shape)\n",
    "print (reaction_nodes.iloc[0:5,0:2])\n",
    "reaction_nodes_dict = dict(zip(reaction_nodes[\"Reaction\"],reaction_nodes.index))\n",
    "print (reaction_nodes_dict[\"R-HSA-5336466\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7e1cf70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Protein         Realation       Reaction  Gene\n",
      "194943  Q9HCJ1  catalystActivity  R-HSA-5226964  ANKH\n",
      "<class 'str'>\n",
      "13702\n",
      "['NIPAL2', 'NIPAL3', 'NIPA2', 'NIPAL4', 'NIPA1', 'NIPAL1']\n",
      "['ANKH']\n"
     ]
    }
   ],
   "source": [
    "## 获取每个样本的节点特征矩阵\n",
    "protein_reaction_file= '/public/ref/Msigdb/Reactome/useInfo/Human.ProteinRoleReaction.txt'\n",
    "prf = pd.read_csv(protein_reaction_file,sep='\\t',header=None)\n",
    "prf.columns = [\"Protein\",'Realation','Reaction']\n",
    "prf[\"Gene\"] = prf['Protein'].apply(lambda x : P2Symbol_dict[x] if x in P2Symbol_dict.keys() else x)\n",
    "reaction_gene_dict = {}\n",
    "print (prf.loc[prf[\"Reaction\"] == 'R-HSA-5226964'])\n",
    "print (type(prf.loc[2,\"Reaction\"]))\n",
    "for i in range(prf.shape[0]):\n",
    "    reaction_gene_dict.setdefault(prf.loc[i,\"Reaction\"],[]).append(prf.loc[i,\"Gene\"]) ## Reaction包含哪些基因\n",
    "    \n",
    "# 错误代码    \n",
    "reaction_gene_dict[prf.loc[i,\"Reaction\"]] = list(set(reaction_gene_dict[prf.loc[i,\"Reaction\"]])) # 去重\n",
    "\n",
    "print (len(reaction_gene_dict))\n",
    "#for i, (k, v) in enumerate(reaction_gene_dict.items()):\n",
    "#    if i in range(0, 3):\n",
    "#        print(k, v)\n",
    "print (reaction_gene_dict[\"R-HSA-5336453\"])\n",
    "print (reaction_gene_dict[\"R-HSA-5226964\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8774f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ANKH']\n",
      "2023-09-11  15:00:35\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35464/4216142796.py:3: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten() ## 幂\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-11  15:01:01\n",
      "1\n",
      "2023-09-11  15:01:28\n",
      "2\n",
      "2023-09-11  15:01:55\n",
      "3\n",
      "2023-09-11  15:02:21\n",
      "4\n",
      "2023-09-11  15:02:47\n",
      "5\n",
      "2023-09-11  15:03:13\n",
      "6\n",
      "2023-09-11  15:03:40\n",
      "7\n",
      "2023-09-11  15:04:06\n",
      "8\n",
      "2023-09-11  15:04:33\n",
      "9\n",
      "2023-09-11  15:04:59\n",
      "10\n",
      "2023-09-11  15:05:25\n",
      "11\n",
      "2023-09-11  15:05:52\n",
      "12\n",
      "2023-09-11  15:06:18\n",
      "13\n",
      "2023-09-11  15:06:45\n",
      "14\n",
      "2023-09-11  15:07:11\n",
      "15\n",
      "2023-09-11  15:07:37\n",
      "16\n",
      "2023-09-11  15:08:03\n",
      "17\n",
      "2023-09-11  15:08:30\n",
      "18\n",
      "2023-09-11  15:08:56\n",
      "19\n",
      "2023-09-11  15:09:22\n",
      "(13589, 9029)\n",
      "20\n",
      "store all sample node features done\n",
      "2023-09-11  15:09:22\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "common_gene_list = set(reaction_gene_list) & set(GTEx_exp.columns)\n",
    "nodes_features = list()\n",
    "#print (type(GTEx_exp))\n",
    "print (reaction_gene_dict[\"R-HSA-5226964\"])\n",
    "#print (\"ANKH\" in normlizeGTEx.columns)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "for index in range(GTEx_exp.shape[0]):\n",
    "    print (index)\n",
    "    sample_node_feature = copy.deepcopy(zero_matrix)\n",
    "    for j in range(sample_node_feature.shape[0]):\n",
    "        reaction_name = reaction_nodes.loc[j,\"Reaction\"]\n",
    "        if (reaction_nodes.loc[j,\"Type\"] != \"ProteinReaction\"):continue\n",
    "        hsa_gene_list = reaction_gene_dict[reaction_name] \n",
    "        for gene in hsa_gene_list:\n",
    "            if (gene in common_gene_list):\n",
    "                sample_node_feature.at[j,gene] = GTEx_exp.at[index,gene]\n",
    "            else:\n",
    "                continue\n",
    "        #break\n",
    "    sample_node_feature = normalize(sp.csr_matrix(sample_node_feature,dtype=np.float32))    \n",
    "    nodes_features.append(torch.tensor(np.array(sample_node_feature.todense()), dtype=torch.float32))\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "    #break\n",
    "print (sample_node_feature.shape)\n",
    "print (len(nodes_features))\n",
    "print (\"store all sample node features done\")\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d  %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "797d9e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13589, 9029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35464/169537596.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[\"sum\"]=a.apply(lambda x:sum(x),axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.000\n",
      "1          4.852\n",
      "2          0.000\n",
      "3          3.792\n",
      "4          0.000\n",
      "          ...   \n",
      "13584      0.137\n",
      "13585    267.447\n",
      "13586      0.000\n",
      "13587     17.128\n",
      "13588      0.000\n",
      "Name: sum, Length: 13589, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (sample_node_feature.shape)\n",
    "a =sample_node_feature.iloc[:,2:sample_node_feature.shape[1]]\n",
    "a[\"sum\"]=a.apply(lambda x:sum(x),axis=1)\n",
    "print (a[\"sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b889528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理内存\n",
    "#del GTEx_exp\n",
    "#del zero_matrix\n",
    "#del normlizeGTEx\n",
    "#del features\n",
    "#del nodes_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "930c628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_labels_onehot 样本标签\n",
    "# nodes_features 各样本节点特征\n",
    "# sample_edges 各样本边的特征\n",
    "edges_file = \"/public/home/liujunwu/workdir/scripts/GNN_Reactome/reaction_file/reactome_reaction.edges.txt\"\n",
    "#sample_edges = np.genfromtxt(\"{}\".format(edges_file), dtype=np.float32)    # 读取边信息\n",
    "edges_pd = pd.read_csv(edges_file,header=None,sep='\\t')\n",
    "edges_pd.columns = [\"Edge1\",\"Edge2\",\"Type\",\"TopLevel\"]\n",
    "#prf[\"Gene\"] = prf['Protein'].apply(lambda x : P2Symbol_dict[x] if x in P2Symbol_dict.keys() else x)\n",
    "#reaction_nodes_dict: store the nodes: index\n",
    "edges_pd[\"Edge1_index\"] = edges_pd[\"Edge1\"].apply(lambda x : reaction_nodes_dict[x])\n",
    "edges_pd[\"Edge2_index\"] = edges_pd[\"Edge2\"].apply(lambda x : reaction_nodes_dict[x])\n",
    "#edges_trans.loc[df[\"Edge2\"]] = edges_trans[\"Edge2\"].apply(lambda x : reaction_nodes_dict[x])\n",
    "edges_trans = edges_pd[[\"Edge1_index\",\"Edge2_index\"]]\n",
    "edges_trans = torch.tensor(np.array(edges_trans), dtype=torch.int64).T\n",
    "#print (edges_trans[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07827bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_onehot = torch.LongTensor(np.where(sample_labels_onehot)[1])                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9043078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 13,  9,  9, 14,  1,  0, 12,  6, 11,  3,  5, 10,  4,  2,  8,  7, 15,\n",
      "        15, 15])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print (sample_labels_onehot)\n",
    "print (len(set(sample_labels_onehot)))\n",
    "# 设置参数和模型定义\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(len(nodes_features), 64, len(sample_labels_onehot))                                               # 节点特征维度，隐藏神经元个数，标签数目\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "331f9fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'todense'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mnodes_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m()), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), edges_trans)    \u001b[38;5;66;03m#模型的输入有节点特征还有边特征,使用的是全部数据\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[idx_train], labels[idx_train])    \u001b[38;5;66;03m#损失仅仅计算的是训练集的损失\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'todense'"
     ]
    }
   ],
   "source": [
    "idx_train = range(15)                                       # 其中2000个点是训练数据                   \n",
    "idx_test = range(15, 20)                                  # 700个测试数据\n",
    "idx_train = torch.LongTensor(idx_train) # 用于表示包含整数（64整型数据）的张量\n",
    "idx_test = torch.LongTensor(idx_test)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(torch.tensor(np.array(nodes_features.todense()), dtype=torch.float32), edges_trans)    #模型的输入有节点特征还有边特征,使用的是全部数据\n",
    "    loss = F.nll_loss(out[idx_train], labels[idx_train])    #损失仅仅计算的是训练集的损失\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch > 250):\n",
    "        print(f\"epoch:{epoch+1}, loss:{loss.item()}\")\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a90dc04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     35    1033]\n",
      " [     35  103482]\n",
      " [     35  103515]\n",
      " ...\n",
      " [ 853118 1140289]\n",
      " [ 853155  853118]\n",
      " [ 954315 1155073]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def  load_data(nodes=\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/test_data/Cora/Cora/cora.content\",edges=\"/public/home/liujunwu/workdir/scripts/GNN_Reactome/test_data/Cora/Cora/cora.cites\"):\n",
    "    idx_features_labels = np.genfromtxt(\"{}\".format(nodes),dtype=np.dtype(str))# 读取节点特征和标签\n",
    "    #print (idx_features_labels[:,-1])\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32) # 读取节点特征\n",
    "    dict = {int(element):i for i,element in enumerate(idx_features_labels[:, 0:1].reshape(-1))}    # 建立字典\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])                       # 节点标签用onehot方式表示\n",
    "    e = np.genfromtxt(\"{}\".format(edges), dtype=np.int32)    # 读取边信息\n",
    "    print (e)\n",
    "    edges = []\n",
    "    for i, x in enumerate(e):\n",
    "        edges.append([dict[e[i][0]], dict[e[i][1]]])                         # 若A->B有边 则B->A 也有边   ### 后续这里要修改？需要是有向图                 \n",
    "        edges.append([dict[e[i][1]], dict[e[i][0]]])                         # 给的数据是没有从0开始需要转换\n",
    "    features = normalize(features)                                           # 特征值归一化       \n",
    "    features = torch.tensor(np.array(features.todense()), dtype=torch.float32)\n",
    "    labels = torch.LongTensor(np.where(labels)[1])                       \n",
    "    edges = torch.tensor(edges, dtype=torch.int64).T\n",
    "    return features, edges, labels\n",
    "features, edges, labels = load_data()\n",
    "print (type(features.numpy()))\n",
    "print (features[0:3])\n",
    "#idx_train = range(2000)                                       # 其中2000个点是训练数据                   \n",
    "#idx_test = range(2000, 2700)                                  # 700个测试数据\n",
    "#idx_train = torch.LongTensor(idx_train) # 用于表示包含整数（64整型数据）的张量\n",
    "#idx_test = torch.LongTensor(idx_test)\n",
    "#print (idx_test.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9cec3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "占用 0.18 KB内存\n"
     ]
    }
   ],
   "source": [
    "def getsizeof(p_object, default=None): # real signature unknown; restored from __doc__\n",
    "    \"\"\"\n",
    "    getsizeof(object [, default]) -> int\n",
    "    \n",
    "    Return the size of object in bytes.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "def binary_conversion(var: int):\n",
    "    \"\"\"\n",
    "    二进制单位转换\n",
    "    :param var: 需要计算的变量，bytes值\n",
    "    :return: 单位转换后的变量，kb 或 mb\n",
    "    \"\"\"\n",
    "    assert isinstance(var, int)\n",
    "    if var <= 1024:\n",
    "        return f'占用 {round(var / 1024, 2)} KB内存'\n",
    "    else:\n",
    "        return f'占用 {round(var / (1024 ** 2), 2)} MB内存'\n",
    "from sys import getsizeof as getsize\n",
    "print (binary_conversion(getsize(nodes_features)))\n",
    "#keys = dir()\n",
    "#for variable in keys:\n",
    "#    print(variable, binary_conversion(getsize(eval(variable))), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "387b854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 163  402]\n",
      " [ 402  163]\n",
      " [ 163  659]\n",
      " ...\n",
      " [1887 1902]\n",
      " [ 837 1686]\n",
      " [1686  837]]\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "print (edges.T.numpy())\n",
    "print (len(features.numpy()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b2aabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,feature,hidden,classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(feature, hidden)  #输入=节点特征维度，hidden是中间隐藏神经元个数\n",
    "        self.conv2 = GCNConv(hidden, classes)\n",
    "    def forward(self, features, edges):\n",
    "        features = self.conv1(features, edges)\n",
    "        features = F.relu(features)\n",
    "        features = F.dropout(features, training=self.training)\n",
    "        features = self.conv2(features, edges)\n",
    "        return F.log_softmax(features, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daa2c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数和模型定义\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(1433, 64, 7)                                               # 节点特征维度，隐藏神经元个数，标签数目\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)               # 梯度优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f5682b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:252, loss:0.3696596324443817\n",
      "epoch:253, loss:0.364935964345932\n",
      "epoch:254, loss:0.3683640658855438\n",
      "epoch:255, loss:0.3657892048358917\n",
      "epoch:256, loss:0.3638060390949249\n",
      "epoch:257, loss:0.3660072982311249\n",
      "epoch:258, loss:0.36475828289985657\n",
      "epoch:259, loss:0.36472803354263306\n",
      "epoch:260, loss:0.36476242542266846\n",
      "epoch:261, loss:0.36531245708465576\n",
      "epoch:262, loss:0.3770420253276825\n",
      "epoch:263, loss:0.3715515434741974\n",
      "epoch:264, loss:0.37264105677604675\n",
      "epoch:265, loss:0.36958810687065125\n",
      "epoch:266, loss:0.36638206243515015\n",
      "epoch:267, loss:0.3630881905555725\n",
      "epoch:268, loss:0.3794698417186737\n",
      "epoch:269, loss:0.369625061750412\n",
      "epoch:270, loss:0.3701733648777008\n",
      "epoch:271, loss:0.3751410245895386\n",
      "epoch:272, loss:0.36737310886383057\n",
      "epoch:273, loss:0.36584511399269104\n",
      "epoch:274, loss:0.378248929977417\n",
      "epoch:275, loss:0.37657520174980164\n",
      "epoch:276, loss:0.3594202995300293\n",
      "epoch:277, loss:0.3686261773109436\n",
      "epoch:278, loss:0.3610154688358307\n",
      "epoch:279, loss:0.3707183599472046\n",
      "epoch:280, loss:0.37201184034347534\n",
      "epoch:281, loss:0.36671310663223267\n",
      "epoch:282, loss:0.36729761958122253\n",
      "epoch:283, loss:0.3690580129623413\n",
      "epoch:284, loss:0.3674565255641937\n",
      "epoch:285, loss:0.35744431614875793\n",
      "epoch:286, loss:0.36719533801078796\n",
      "epoch:287, loss:0.36727699637413025\n",
      "epoch:288, loss:0.3681260645389557\n",
      "epoch:289, loss:0.3660051226615906\n",
      "epoch:290, loss:0.3741512894630432\n",
      "epoch:291, loss:0.3635961413383484\n",
      "epoch:292, loss:0.3731101453304291\n",
      "epoch:293, loss:0.3686520457267761\n",
      "epoch:294, loss:0.365024596452713\n",
      "epoch:295, loss:0.3724896311759949\n",
      "epoch:296, loss:0.3617793619632721\n",
      "epoch:297, loss:0.37341615557670593\n",
      "epoch:298, loss:0.3710658550262451\n",
      "epoch:299, loss:0.3721224367618561\n",
      "epoch:300, loss:0.37016260623931885\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "model.train()\n",
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(features, edges)    #模型的输入有节点特征还有边特征,使用的是全部数据\n",
    "    loss = F.nll_loss(out[idx_train], labels[idx_train])    #损失仅仅计算的是训练集的损失\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch > 250):\n",
    "        print(f\"epoch:{epoch+1}, loss:{loss.item()}\")\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4bdd318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557142857142858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntest_predict = model(data.x, data.edge_index)[data.test_mask]\\nmax_index = torch.argmax(test_predict, dim=1)\\ntest_true = data.y[data.test_mask]\\ncorrect = 0\\nfor i in range(len(max_index)):\\n    if max_index[i] == test_true[i]:\\n        correct += 1\\nprint('测试集准确率为：{}%'.format(correct*100/len(test_true)\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试：\n",
    "model.eval()\n",
    "_,pred = model(features,edges).max(dim=1)\n",
    "\n",
    "correct = pred[idx_test].eq(labels[idx_test]).sum()            # 计算预测与标签相等个数\n",
    "acc = int(correct) / int(len(idx_test))                        # 计算正确率\n",
    "print(acc)\n",
    "# 另一种写法\n",
    "'''\n",
    "test_predict = model(data.x, data.edge_index)[data.test_mask]\n",
    "max_index = torch.argmax(test_predict, dim=1)\n",
    "test_true = data.y[data.test_mask]\n",
    "correct = 0\n",
    "for i in range(len(max_index)):\n",
    "    if max_index[i] == test_true[i]:\n",
    "        correct += 1\n",
    "print('测试集准确率为：{}%'.format(correct*100/len(test_true)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdac4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "x = [[-1],[0],[1]]\n",
    "print (type(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
